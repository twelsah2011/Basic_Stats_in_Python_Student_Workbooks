{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \t\n",
    "import matplotlib.pyplot as plt \n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fractions import Fraction\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes - From Scratch\n",
    "\n",
    "We can expand on the the idea of Bayesean updates with multiple features into a full predictive model. Naive Bayes is one of the most simple predictive algorithms, as it is little more than the Bayes table based updates that we can calculate by hand. \n",
    "\n",
    "We'll look at this in a two step process:\n",
    "<ul>\n",
    "<li> Create a slightly expanded Bayes table update, that deals with multiple features at once. \n",
    "<li> Expand that concpet into a full prediction machine. \n",
    "</ul>\n",
    "\n",
    "The difference between the two is that when creating the model version, we calculate all of the probabilities we might need in advance (the training step), the actual calculation of a prediction is almost the same. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 樸素貝葉斯 - 從零開始\n",
    "\n",
    "我們可以將具有多個特徵的貝葉斯更新的想法擴展到一個完整的預測模型中。 樸素貝葉斯是最簡單的預測算法之一，因為它只不過是我們可以手動計算的基於貝葉斯表的更新。\n",
    "\n",
    "我們將分兩步來看：\n",
    "<ul>\n",
    "<li> 創建一個稍微擴展的貝葉斯表更新，一次處理多個特徵。\n",
    "<li> 將該概念擴展為完整的預測機器。\n",
    "</ul>\n",
    "\n",
    "兩者之間的區別在於，在創建模型版本時，我們預先計算了所有可能需要的概率（訓練步驟），實際計算預測幾乎相同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Udate Function and Load Data\n",
    "\n",
    "We'll use the weather data from last time, and make predictions both via tables and then a real model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Windy</th>\n",
       "      <th>Play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>f</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>t</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>f</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>f</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>f</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Outlook  Temp Humidity Windy Play\n",
       "0     Rainy   Hot     High     f   no\n",
       "1     Rainy   Hot     High     t   no\n",
       "2  Overcast   Hot     High     f  yes\n",
       "3     Sunny  Mild     High     f  yes\n",
       "4     Sunny  Cool   Normal     f  yes"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update(table):\n",
    "    \"\"\"Compute the posterior probabilities.\"\"\"\n",
    "    table['unnorm'] = table['prior'] * table['likelihood']\n",
    "    prob_data = table['unnorm'].sum()\n",
    "    table['posterior'] = table['unnorm'] / prob_data\n",
    "    return prob_data\n",
    "\n",
    "df = pd.read_table(\"data/weather.txt\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Bayes Updates\n",
    "\n",
    "We can do a warm-up to making our model by making an update table simplified version. \n",
    "\n",
    "What is the probability of playing when the weather is <b>Sunny, Hot, Normal, False (wind)?</b>\n",
    "\n",
    "##### Build Table with Outcome Prior Probabilities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 表貝葉斯更新\n",
    "\n",
    "我們可以通過製作更新表簡化版本來熱身製作我們的模型。\n",
    "\n",
    "當天氣為<b>Sunny, Hot, Normal, False (wind)時播放的概率是多少？</b>\n",
    "\n",
    "##### 用結果先驗概率建表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Play</th>\n",
       "      <td>9/14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not Play</th>\n",
       "      <td>5/14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prior\n",
       "Play      9/14\n",
       "Not Play  5/14"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = pd.DataFrame(index=[\"Play\", \"Not Play\"])\n",
    "total = len(df)\n",
    "dfPlay = df[df[\"Play\"] == \"yes\"]\n",
    "dfNoPlay = df[df[\"Play\"] == \"no\"]\n",
    "pPlay = Fraction(len(df[df[\"Play\"] == \"yes\"]), total)\n",
    "weather[\"prior\"] = pPlay, (1 - pPlay)\n",
    "updates = 1\n",
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>unnorm</th>\n",
       "      <th>posterior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Play</th>\n",
       "      <td>9/14</td>\n",
       "      <td>1/3</td>\n",
       "      <td>3/14</td>\n",
       "      <td>3/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not Play</th>\n",
       "      <td>5/14</td>\n",
       "      <td>2/5</td>\n",
       "      <td>1/7</td>\n",
       "      <td>2/5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prior likelihood unnorm posterior\n",
       "Play      9/14        1/3   3/14       3/5\n",
       "Not Play  5/14        2/5    1/7       2/5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if_playOut = Fraction(len(dfPlay[dfPlay[\"Outlook\"] == \"Sunny\"]), len(dfPlay))\n",
    "if_notOut = Fraction(len(dfNoPlay[dfNoPlay[\"Outlook\"] == \"Sunny\"]), len(dfNoPlay))\n",
    "weather[\"likelihood\"] = if_playOut, if_notOut\n",
    "update(weather)\n",
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update Table\n",
    "\n",
    "We'll tweak the prevous update steps to handle multiple rounds. (This isn't the most efficient way to do this, we're digging through the details here.) We will run the updates just as we did before, the change here is each time I'll rename the old prior and likelihood values, so we keep everything in a larger, growing table, as we go though. \n",
    "\n",
    "Because the likelihoods are all going to be multiplied with each other, we'll hold on to all of those values for later. \n",
    "\n",
    "<b>Note:</b> The renaming pattern is so we can keep the expected column names and reuse that same update function. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####更新表\n",
    "\n",
    "我們將調整先前的更新步驟以處理多輪。 （這不是執行此操作的最有效方法，我們正在此處挖掘詳細信息。）\n",
    "\n",
    "我們將像以前一樣運行更新，這裡的更改是每次我將重命名舊的先驗值和似然值 ，\n",
    "\n",
    "因此我們將所有內容保存在一個更大的、不斷增長的表中。\n",
    "\n",
    "因為可能性都會相互成倍增加，所以我們稍後會保留所有這些值。\n",
    "\n",
    "<b>注意：</b>重命名模式是為了讓我們可以保留預期的列名並重用相同的更新函數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior1</th>\n",
       "      <th>likelihood1</th>\n",
       "      <th>prior</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>unnorm</th>\n",
       "      <th>posterior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Play</th>\n",
       "      <td>9/14</td>\n",
       "      <td>1/3</td>\n",
       "      <td>3/14</td>\n",
       "      <td>2/9</td>\n",
       "      <td>1/21</td>\n",
       "      <td>5/11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not Play</th>\n",
       "      <td>5/14</td>\n",
       "      <td>2/5</td>\n",
       "      <td>1/7</td>\n",
       "      <td>2/5</td>\n",
       "      <td>2/35</td>\n",
       "      <td>6/11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prior1 likelihood1 prior likelihood unnorm posterior\n",
       "Play       9/14         1/3  3/14        2/9   1/21      5/11\n",
       "Not Play   5/14         2/5   1/7        2/5   2/35      6/11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = weather.rename(columns={\"prior\": str(\"prior\"+str(updates)), \"unnorm\": \"prior\", \"likelihood\":(\"likelihood\"+str(updates))})\n",
    "weather = weather.drop(columns={\"posterior\"})\n",
    "updates += 1\n",
    "if_playTemp = Fraction(len(dfPlay[dfPlay[\"Temp\"] == \"Hot\"]), len(dfPlay))\n",
    "if_notTemp = Fraction(len(dfNoPlay[dfNoPlay[\"Temp\"] == \"Hot\"]), len(dfNoPlay))\n",
    "weather[\"likelihood\"] = if_playTemp, if_notTemp\n",
    "update(weather)\n",
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Another Update\n",
    "\n",
    "Remove the posterior probability, rename the likelihood and prior probability from the last update round. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior1</th>\n",
       "      <th>likelihood1</th>\n",
       "      <th>prior2</th>\n",
       "      <th>likelihood2</th>\n",
       "      <th>prior3</th>\n",
       "      <th>likelihood3</th>\n",
       "      <th>prior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Play</th>\n",
       "      <td>9/14</td>\n",
       "      <td>1/3</td>\n",
       "      <td>3/14</td>\n",
       "      <td>2/9</td>\n",
       "      <td>1/21</td>\n",
       "      <td>2/3</td>\n",
       "      <td>2/63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not Play</th>\n",
       "      <td>5/14</td>\n",
       "      <td>2/5</td>\n",
       "      <td>1/7</td>\n",
       "      <td>2/5</td>\n",
       "      <td>2/35</td>\n",
       "      <td>1/5</td>\n",
       "      <td>2/175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prior1 likelihood1 prior2 likelihood2 prior3 likelihood3  prior\n",
       "Play       9/14         1/3   3/14         2/9   1/21         2/3   2/63\n",
       "Not Play   5/14         2/5    1/7         2/5   2/35         1/5  2/175"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = weather.rename(columns={\"prior\": str(\"prior\"+str(updates)), \"unnorm\": \"prior\", \"likelihood\":(\"likelihood\"+str(updates))})\n",
    "weather = weather.drop(columns={\"posterior\"})\n",
    "updates += 1\n",
    "if_playHum2 = Fraction(len(dfPlay[dfPlay[\"Humidity\"] == \"Normal\"]) , len(dfPlay))\n",
    "if_notHum2 = Fraction(len(dfNoPlay[dfNoPlay[\"Humidity\"] == \"Normal\"]) , len(dfNoPlay))\n",
    "weather[\"likelihood\"] = if_playHum2, if_notHum2\n",
    "update(weather)\n",
    "weather = weather.rename(columns={\"prior\": str(\"prior\"+str(updates)), \"unnorm\": \"prior\", \"likelihood\":(\"likelihood\"+str(updates))})\n",
    "weather = weather.drop(columns={\"posterior\"})\n",
    "updates += 1\n",
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last Update Step\n",
    "\n",
    "After this update I'll keep the posterior probability, since we are done, and I'll drop all the interim prior probabilities since we have no use for them. We will keep the likelihoods, as that set of likelihoods is ultimately all we need to generate predictions. \n",
    "\n",
    "Note the final probabilities at the end, either the unnormalized or the posterior probabilities, our categorization prediction will be whichever of those probabilities is larger. Well, if we flash back to the actual Bayes equation:\n",
    "\n",
    "![Naive Bayes](images/naive_bayes.png \"Naive Bayes\")\n",
    "\n",
    "The numerator of that equation is just the prior probability and all of the likelihoods multiplied together, which is the set of values that we have. The denominator of the equation is the same for any outcome, so if we consider it or ignore it doesn't matter - all it does is allow us to normalize the probabilities, which as we can see from the table, we don't need. So... we can make our predictions in general by just calculating all of those likelihoods and the prior probability, multiplying throuhg, and choosing the largest result. \n",
    "\n",
    "<b> The Naive Bayes predictive model is just a generalized form of this.</b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最後更新步驟\n",
    "\n",
    "在這次更新之後，我將保留後驗概率，因為我們已經完成了，並且我將放棄所有臨時先驗概率，因為我們對它們沒有用。 我們將保留可能性，因為這組可能性最終是我們生成預測所需的全部。\n",
    "\n",
    "注意最後的最終概率，無論是非歸一化概率還是後驗概率，我們的分類預測將是這些概率中較大的一個。 好吧，如果我們回顧實際的貝葉斯方程：\n",
    "\n",
    "![樸素貝葉斯](images/naive_bayes.png \"樸素貝葉斯\")\n",
    "\n",
    "該等式的分子就是先驗概率和所有可能性相乘，這就是我們擁有的一組值。 等式的分母對於任何結果都是相同的，所以我們考慮或忽略它都沒有關係——它所做的只是允許我們對概率進行歸一化，正如我們從表中看到的那樣，我們不需要 . 所以……我們可以通過計算所有這些可能性和先驗概率、相乘並選擇最大的結果來做出一般性的預測。\n",
    "\n",
    "<b> 樸素貝葉斯預測模型只是此模型的一般化形式。</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior1</th>\n",
       "      <th>likelihood1</th>\n",
       "      <th>likelihood2</th>\n",
       "      <th>likelihood3</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>unnorm</th>\n",
       "      <th>posterior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Play</th>\n",
       "      <td>9/14</td>\n",
       "      <td>1/3</td>\n",
       "      <td>2/9</td>\n",
       "      <td>2/3</td>\n",
       "      <td>2/3</td>\n",
       "      <td>4/189</td>\n",
       "      <td>125/152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not Play</th>\n",
       "      <td>5/14</td>\n",
       "      <td>2/5</td>\n",
       "      <td>2/5</td>\n",
       "      <td>1/5</td>\n",
       "      <td>2/5</td>\n",
       "      <td>4/875</td>\n",
       "      <td>27/152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prior1 likelihood1 likelihood2 likelihood3 likelihood unnorm  \\\n",
       "Play       9/14         1/3         2/9         2/3        2/3  4/189   \n",
       "Not Play   5/14         2/5         2/5         1/5        2/5  4/875   \n",
       "\n",
       "         posterior  \n",
       "Play       125/152  \n",
       "Not Play    27/152  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if_playWind2 = Fraction(len(dfPlay[dfPlay[\"Windy\"] == \"f\"]) , len(dfPlay))\n",
    "if_notWind2 = Fraction(len(dfNoPlay[dfNoPlay[\"Windy\"] == \"f\"]) , len(dfNoPlay))\n",
    "weather[\"likelihood\"] = if_playWind2, if_notWind2\n",
    "update(weather)\n",
    "weather.drop(columns={\"prior2\", \"prior\", \"prior3\"}, inplace=True)\n",
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/189\n"
     ]
    }
   ],
   "source": [
    "# Self Check\n",
    "# Play unnormalized probabilities\n",
    "print(Fraction(9,14)*Fraction(1,3)*Fraction(2,9)*Fraction(2,3)*Fraction(2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "What we are left with here is a series of likelihoods that each modify our prior probability. If we're keen, we also notice that this series of likelihoods translates directly to the top part of the Bayes equation. The bottom bit is always the same, and we only need that to normalize, so the result of the prediction is whichever unnorm probability is higher. Here 4/189 is more likely than 4/875, so we predict we'll play. \n",
    "\n",
    "This is all our classifier needs to do! We just take the prior probabilities and all the likelihoods, multiply them through, and pick the most likely outcome!! This should be pretty easy to put into place:\n",
    "<ul>\n",
    "<li> <b>Fitting the Model:</b> The training part of the model can just calculate all of these likelihoods and prior probabilities. Each one was just simple math, so we'll calculate all of them and store them in some kind of list (a dictionary, actually).\n",
    "    <ul>\n",
    "    <li> E.g. the likelihood of playing golf if it is sunny can be calculated and saved, same with the prob of not playing if it is windy, etc...\n",
    "    </ul>\n",
    "<li> <b>Making Predictions:</b> The predicting part is just looking up the prior and the matching likelihoods from our dictionary of precalculated values, and doing the math. \n",
    "</ul>\n",
    "\n",
    "We are awesome!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＃＃＃ 結果\n",
    "\n",
    "我們在這裡剩下的是一系列可能性，每個可能性都會修改我們的先驗概率。 \n",
    "\n",
    "如果我們很敏銳，我們還會注意到這一系列的可能性直接轉化為貝葉斯方程的頂部。 \n",
    "\n",
    "底部位總是相同的，我們只需要對其進行歸一化，因此預測的結果是哪個非歸一化概率較高。 \n",
    "\n",
    "這裡 4/189 比 4/875 更有可能，所以我們預測我們會玩。\n",
    "\n",
    "這就是我們的分類器需要做的所有事情！ \n",
    "\n",
    "我們只是採用先驗概率和所有可能性，將它們相乘，然後選擇最有可能的結果！！ 這應該很容易到位：\n",
    "<ul>\n",
    "<li> <b>擬合模型：</b>模型的訓練部分可以計算所有這些可能性和先驗概率。 \n",
    "\n",
    "每一個都只是簡單的數學運算，所以我們將計算所有這些並將它們存儲在某種列表（實際上是字典）中。\n",
    "     <ul>\n",
    "     <li> 例如 如果天氣晴朗，可以計算並保存打高爾夫球的可能性，如果有風，則可以計算不打高爾夫球的可能性等......\n",
    "     </ul>\n",
    "<li> <b>進行預測：</b> 預測部分只是從我們的預先計算值的字典中查找先驗和匹配可能性，然後進行數學計算。\n",
    "</ul>\n",
    "\n",
    "我們很棒！"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Naive Bayes\n",
    "\n",
    "### Parts of the Model\n",
    "\n",
    "Our predictive model needs to do a few things. The main conceptual difference between this model and doing the Bayes tables is that here we will pre-calculate all of the potential calculations of likelihood that we may need. In the tables, every time we saw a new feature we then calculated its likelihood and updated our probability with it when we did the update to generate the unnormalized and posterior probabilities. Here we will pre-calculate each of those likelihoods ahead of time in the fitting step, so when a prediction needs to be made we can just look up the matching likelihoods and do the multiplication to calculate the answer. Doing it like this means all of the heavy lifting (calculating all of the probabilities) is done while fitting, and creating predictions is fast. \n",
    "\n",
    "### Initialization\n",
    "\n",
    "The initialization step will just setup the pieces that we'll need. Here our initialization declares empty varaibles that will hold everything we calculate and figure out. \n",
    "\n",
    "初始化步驟將只設置我們需要的部分。 \n",
    "\n",
    "在這裡，我們的初始化聲明了空變量，它將保存我們計算和計算出的所有內容。\n",
    "\n",
    "### Train the Model\n",
    "\n",
    "The training process is where the model is \"built\", or where it learns all of the information it needs to be able to make predictions. This is the majority of the work. In short, we need to:\n",
    "<ul>\n",
    "<li> <b>Create a list of all the features in our data. </b>\n",
    "<li> <b>Create a list of all of the likelihood possibilities. </b>\n",
    "    <ul>\n",
    "    <li> This is a list of all the potential featureValue_outcome pairs that is possible. \n",
    "    <li> The format, with an underscore between the feature and value is arbitrary - we are only creating a replicable item to represent that combination, it could theoretically be anything. \n",
    "    </ul>\n",
    "<li> <b>Calculate the actual likelihood probabilities. </b>\n",
    "    <ul>\n",
    "    <li> For each of the possible likelihoods, calculate its actual likelihood value. \n",
    "    <li> I.e. what is the actual probability of playing golf given that it is sunny.\n",
    "    <li> This is the \"flipped conditional\" part of the Bayes equation. \n",
    "    </ul>\n",
    "<li> <b>Calculate outcome class prior probabilities. </b>\n",
    "    <ul>\n",
    "    <li> This is the other part of the numerator in the Bayes equation. \n",
    "    </ul>\n",
    "<li> <b>Calculate the prior probabilities for the features. </b>\n",
    "    <ul>\n",
    "    <li> How likely is each potential value for each feature. \n",
    "    <li> Used for the bottom of the Bayes equation. \n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "Once done training, no matter what our data actually says, we should have all of the probabilities for it pre-calculated in one of our data structures. \n",
    "\n",
    "### Predict\n",
    "\n",
    "To make a prediction we just need to look up the correct probabilities, and perform the calculation. We can lookup:\n",
    "<ul><b>\n",
    "<li> The outcome prior probability. \n",
    "<li> Each likelihood. (Flipped conditional)\n",
    "<li> Each feature prior probability\n",
    "</b></ul>\n",
    "\n",
    "$ P(A | B1,B2,B3) = \\frac{P(A)*P(B1|A)*P(B2|A)*P(B3|A)}{P(B1)*P(B2)*P(B3)} $\n",
    "\n",
    "The math to then make a prediction is easy, we can predict the probability for each class by multiplying the outcome prior prob and the likelihoods, then divide by the product of the feature priors to normalize. Highest probability outcome is the prediction. This makes the calculation of the predictions very quick. \n",
    "\n",
    "#### Important Bayes Note\n",
    "\n",
    "One problem that can occur with Bayes is the \"zero count\" problem, or what if we have a valid value for one of our features that just doesn't occur in our training data. For example, what if there was a day that we were predicting with our weather and golf model where the Humidity was \"Dry\"? When we attempt to look up the probability of \"Humidity = Dry\" there won't be anything there and the probability will be 0, since we didn't train for it. Since this will popup on the bottom of the division in the equation, that'll be an issue. This problem is resolved through something called Laplace (or Additive) Smoothing. We won't implement this immediately here (maybe next week? maybe for a fun weekend exercise?) but the idea is relatively simple - when calculating the probability of something, rather than doing the normal calculation of:\n",
    "\n",
    "$ P(A) = \\frac{countA}{totalElements} $\n",
    "\n",
    "We change that to:\n",
    "\n",
    "$ P(A) = \\frac{countA + alpha}{totalElements + (alpha*numberFeatures)} $\n",
    "\n",
    "Where alpha is a chosen constant, usually 1. We'll look at how to choose a good alpha when we look at tuning models, the short answer is guess and test. \n",
    "\n",
    "This smoothing correction seves to make sure that our model can handle new values without just failing, at the expense of a very minor impact to accuracy on predicted probabilities for things we do know. If a new unseen value comes in, rather than it's probability being 0, which will cause the overall cacluation to fail, its probability will be some small value - almost certainly unlikely to make a tangible difference in our calculations, but enough to keep things rolling. In other words we've sacrificed a tiny bit of accuracy in exchange for much more generalizability. With datasets of a reasonable size, the small additions of the smoothing calculation don't make much of a difference. \n",
    "\n",
    "In a perfect world, where we knew every possibility ahead of time and had it embedded in our training data, this smoothing would not be useful and we would not consider it. In reality, Bayes is often used for things like spam detection, where the incoming features are words from the text of an email - in such a case, it is very likely that we will encounter new things when making predictions, so this smoothing is used very frequently when using a Naive Bayes model. \n",
    "\n",
    "### Naive Differences\n",
    "\n",
    "Below we have most of the Naive Bayes algorithm. The \"real\" ones from sklearn or other packages are basically the same as this - normally just with slightly better error handling, a few more options, and maybe some optimizations for speed - but the idea and execution is almost the same. One change that is actually different in ours is that we are using data in its dataframe format within our algorithm. This is a relatively minor change, and doesn't change any of the concepts behind what we are doing, what it does is make the code a little easier to read and understand as humans, as we can use things like the dataframe's \"columns\" variable. An implementation using arrays (to work exactly like the sklearn ones) would be almost the same, but places where we refer to columns by names would be replaced by indicies. (In practice, many of the functions can take anything that is \"iterable\", or can be iterated over one object at a time, like a dataframe, array, or list: https://www.pythonlikeyoumeanit.com/Module2_EssentialsOfPython/Iterables.html)\n",
    "\n",
    "We can use some print statements to look at exactly what is going on inside our model. This is also a good exercise as if we can't figure something out, printing the current state is the easiest way to diagnose it. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Complete the Algorithm\n",
    "\n",
    "There are a few places in the algorithm below where we need to fill in the last little bit. Most of the code is there, but the last couple of calculations are needed. Try to look through the commented code, and figure out what the missing bits should be. Some guidelines:\n",
    "<ul>\n",
    "<li> The missing calculations are denoted by ##!!!!!!!!!!!!!!!!!!!!!!!\n",
    "<li> Each calculation is recognizable from the Bayes calculations that we'd do by hand. \n",
    "<li> Try to read and make sense of what is happening, the struggle of trying to read the code and make sense of it is not pure sadism on my part, it is a useful exercise. \n",
    "<li> The solution file has answers. \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class  NaiveBayes(object):\n",
    "\tdef __init__(self):\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\t\tAttributes:\n",
    "\t\t\t\tlikelihoods: Likelihood of each feature per class\n",
    "\t\t\t\tclass_priors: Prior probabilities of classes \n",
    "\t\t\t\tpred_priors: Prior probabilities of features \n",
    "\t\t\t\tfeatures: All features of dataset\n",
    "\t\t\t屬性：\n",
    "\t\t\t\tlikelihoods: 每個類的每個特徵的可能性\n",
    "\t\t\t\tclass_priors: 類的先驗概率\n",
    "\t\t\t\tpred_priors: 特徵的先驗概率\n",
    "\t\t\t\tfeatures: 數據集的所有特徵\n",
    "\t\t\"\"\"\n",
    "\t\tself.features = list\n",
    "\t\tself.likelihoods = {} # All of the possible feature-value pairs\n",
    "\t\tself.class_priors = {} # All class priors\n",
    "\t\tself.pred_priors = {} # All the predictor priors (for the bottom)\n",
    "\n",
    "\t\tself.X_train = np.array\n",
    "\t\tself.y_train = np.array\n",
    "\t\tself.train_size = int\n",
    "\t\tself.num_feats = int\n",
    "\n",
    "\tdef fit(self, X, y):\n",
    "\n",
    "\t\tself.features = list(X.columns)\n",
    "\t\tself.X_train = X\n",
    "\t\tself.y_train = y\n",
    "\t\tself.train_size = X.shape[0]\n",
    "\t\tself.num_feats = X.shape[1]\n",
    "\n",
    "\t\t# Generate a list of all the possible \"likelihoods\"\n",
    "\t\t# Each one is a feature_outcome pair, e.g. from the golf\n",
    "\t\t# one: Outlook_sunny, Temperature_hot, etc...\n",
    "\t\tfor feature in self.features:\n",
    "\t\t\t# Initialize the list of possible values for each feature in the big dictionary of features. \n",
    "\t\t\tself.likelihoods[feature] = {}\n",
    "\t\t\tself.pred_priors[feature] = {}\n",
    "\n",
    "\t\t\t# Loop through all of the values that this feature can take on, and add that\n",
    "\t\t\t# as a possibility to the list of likelihoods for that feature. \n",
    "\t\t\tfor feat_val in np.unique(self.X_train[feature]):\n",
    "\t\t\t\tself.pred_priors[feature].update({feat_val: 0})\n",
    "\t\t\t\t#print(feat_val)\n",
    "\t\t\t\tfor outcome in np.unique(self.y_train):\n",
    "\t\t\t\t\tself.likelihoods[feature].update({feat_val+'_'+outcome:0})\n",
    "\t\t\t\t\tself.class_priors.update({outcome: 0})\n",
    "\t\t\t\t\t#print('\\t'+feat_val+'_'+outcome)\n",
    "\t\t\n",
    "\t\t# These functions build the rest of the \"learned knowledge\" of the model. \n",
    "\t\t# Calculate the priors \n",
    "\t\tself._calc_class_prior()\n",
    "\t\t# Calculate the probability of each likelihood\n",
    "\t\t# We precalculate and save each one so when predictions come\n",
    "\t\t# we can just look up the probabilities and multiply. \n",
    "\t\tself._calc_likelihoods()\n",
    "\t\t# Generate prior probs for each feature\n",
    "\t\tself._calc_predictor_prior()\n",
    "\n",
    "\tdef _calc_class_prior(self): # calculate yes or no\n",
    "\n",
    "\t\t\"\"\" P(c) - Prior Class Probability \"\"\"\n",
    "\t\tprint(\"\\nOutcome Priors:\")\n",
    "\t\t# Loop through each outcome\n",
    "\t\t# Count the occurances to determine prior for the outcome\n",
    "\t\tfor outcome in np.unique(self.y_train):\n",
    "\t\t\toutcome_count = sum(self.y_train == outcome)\n",
    "\t\t\tself.class_priors[outcome] = outcome_count / self.train_size ##probability\n",
    "\t\t\tprint(outcome, outcome_count)\n",
    "\n",
    "\tdef _calc_likelihoods(self): #Potential how like it is\n",
    "\n",
    "\t\t\"\"\" P(x|c) - Likelihood \"\"\"\n",
    "\t\tprint(\"\\nLikelihoods:\")\n",
    "\t\t# Loop through each feature\n",
    "\t\tfor feature in self.features:\n",
    "\t\t\tprint(\"\\tLikelihoods for:\", feature)\n",
    "\t\t\t# Loop through each outcome of each feature\n",
    "\t\t\tfor outcome in np.unique(self.y_train):\n",
    "\t\t\t\toutcome_count = sum(self.y_train == outcome)\n",
    "\t\t\t\t# all the likelihood that is possible\n",
    "\t\t\t\tfeat_likelihood = self.X_train[feature][self.y_train[self.y_train == outcome].index.values.tolist()].value_counts().to_dict()\n",
    "\t\t\t\tprint(\"\\t\\tOutcome:\", outcome, outcome_count)\n",
    "\t\t\t\t# Loop through each feature value and calculate its probability\n",
    "\t\t\t\t# A.K.A. the probability conditional on the above outcome\n",
    "\t\t\t\tfor feat_val, count in feat_likelihood.items():\n",
    "\t\t\t\t\tself.likelihoods[feature][feat_val + '_' + outcome] = count/outcome_count ##\n",
    "\t\t\t\t\tprint(\"\\t\\t\\tFeature Value, Count, and Prob:\", feat_val, count, count/outcome_count)\n",
    "\n",
    "\tdef _calc_predictor_prior(self):\n",
    "\n",
    "\t\t\"\"\" P(x) - Evidence \"\"\"\n",
    "\t\tprint(\"\\nFeature Priors:\")\n",
    "\t\t# Loop through each feature\n",
    "\t\tfor feature in self.features:\n",
    "\t\t\tfeat_vals = self.X_train[feature].value_counts().to_dict()\n",
    "\t\t\tprint(\"\\tFeature:\", feature)\n",
    "\t\t\t# Loop through each value for the feature, and caclualte proability. \n",
    "\t\t\t# Feature priors, aka the bottom of bayes\n",
    "\t\t\tfor feat_val, count in feat_vals.items():\n",
    "\t\t\t\tself.pred_priors[feature][feat_val] = count/self.train_size  ## \n",
    "\t\t\t\t#print(self.pred_priors[feature][feat_val])\n",
    "\t\t\t\tprint(\"\\t\\tValue, Count, and Prob:\", feat_val, count, count/self.train_size)\n",
    "\n",
    "\tdef predict(self, X):\n",
    "\n",
    "\t\t\"\"\" Calculates Posterior probability P(c|x) \"\"\"\n",
    "\t\t# Make predictions:\n",
    "\t\t# look up each likelihood, multiply out the likelihood\n",
    "\t\t# normalize and make a prediction of the highest. \n",
    "\t\tresults = []\n",
    "\t\tX = np.array(X)\n",
    "\t\tprint(\"\\nPredictions:\")\n",
    "\t\t# Loop through the things that we are predicting. \n",
    "\t\t# Each query is one record from X, our dataset of features. \n",
    "\t\tfor query in X:\n",
    "\t\t\tprobs_outcome = {}\n",
    "\t\t\tfor outcome in np.unique(self.y_train):\n",
    "\t\t\t\t# Get the prior probability of the outcome\n",
    "\t\t\t\tprior = self.class_priors[outcome]\n",
    "\t\t\t\tlikelihood = 1\n",
    "\t\t\t\tevidence = 1\n",
    "\n",
    "\t\t\t\t# Loop through each feature, and its value. \n",
    "\t\t\t\t# get the likelihood for that feature, \n",
    "\t\t\t\t# update the running probability with that likelihood. \n",
    "\t\t\t\tfor feat, feat_val in zip(self.features, query):\n",
    "\t\t\t\t\tlikelihood *= self.likelihoods[feat][feat_val + '_' + outcome]\n",
    "\t\t\t\t\tevidence *= self.pred_priors[feat][feat_val]\n",
    "\n",
    "\t\t\t\t# This is the Bayes final calculation\n",
    "\t\t\t\tposterior = (likelihood * prior) / (evidence)  ##\n",
    "\t\t\t\t# store the postirior probability in the array of the results. \n",
    "\t\t\t\t# each row of data we are predicting gets a prediction, so we end up with a bunch. \n",
    "\t\t\t\tprobs_outcome[outcome] = posterior\n",
    "\n",
    "\t\t\t# Translate the posterior probs to a prediction i.e. what is the actual predicted class. \n",
    "\t\t\t# The prediction is whichever outcome is most likely. \n",
    "\t\t\tresult = max(probs_outcome, key = lambda x: probs_outcome[x])\n",
    "\t\t\tresults.append(result)\n",
    "\t\t# Return an array of all the predictions, just like we are used to getting from any model\n",
    "\t\treturn np.array(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(df):\n",
    "\n",
    "\t\"\"\" partioning data into features and target \"\"\"\n",
    "\n",
    "\tX = df.drop([df.columns[-1]], axis = 1)\n",
    "\ty = df[df.columns[-1]]\n",
    "\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the Model\n",
    "\n",
    "Load the data, train the model, check the training accuracy, and run a few tests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outcome Priors:\n",
      "no 5\n",
      "yes 9\n",
      "\n",
      "Likelihoods:\n",
      "\tLikelihoods for: Outlook\n",
      "\t\tOutcome: no 5\n",
      "\t\t\tFeature Value, Count, and Prob: Rainy 3 0.6\n",
      "\t\t\tFeature Value, Count, and Prob: Sunny 2 0.4\n",
      "\t\tOutcome: yes 9\n",
      "\t\t\tFeature Value, Count, and Prob: Overcast 4 0.4444444444444444\n",
      "\t\t\tFeature Value, Count, and Prob: Sunny 3 0.3333333333333333\n",
      "\t\t\tFeature Value, Count, and Prob: Rainy 2 0.2222222222222222\n",
      "\tLikelihoods for: Temp\n",
      "\t\tOutcome: no 5\n",
      "\t\t\tFeature Value, Count, and Prob: Hot 2 0.4\n",
      "\t\t\tFeature Value, Count, and Prob: Mild 2 0.4\n",
      "\t\t\tFeature Value, Count, and Prob: Cool 1 0.2\n",
      "\t\tOutcome: yes 9\n",
      "\t\t\tFeature Value, Count, and Prob: Mild 4 0.4444444444444444\n",
      "\t\t\tFeature Value, Count, and Prob: Cool 3 0.3333333333333333\n",
      "\t\t\tFeature Value, Count, and Prob: Hot 2 0.2222222222222222\n",
      "\tLikelihoods for: Humidity\n",
      "\t\tOutcome: no 5\n",
      "\t\t\tFeature Value, Count, and Prob: High 4 0.8\n",
      "\t\t\tFeature Value, Count, and Prob: Normal 1 0.2\n",
      "\t\tOutcome: yes 9\n",
      "\t\t\tFeature Value, Count, and Prob: Normal 6 0.6666666666666666\n",
      "\t\t\tFeature Value, Count, and Prob: High 3 0.3333333333333333\n",
      "\tLikelihoods for: Windy\n",
      "\t\tOutcome: no 5\n",
      "\t\t\tFeature Value, Count, and Prob: t 3 0.6\n",
      "\t\t\tFeature Value, Count, and Prob: f 2 0.4\n",
      "\t\tOutcome: yes 9\n",
      "\t\t\tFeature Value, Count, and Prob: f 6 0.6666666666666666\n",
      "\t\t\tFeature Value, Count, and Prob: t 3 0.3333333333333333\n",
      "\n",
      "Feature Priors:\n",
      "\tFeature: Outlook\n",
      "\t\tValue, Count, and Prob: Rainy 5 0.35714285714285715\n",
      "\t\tValue, Count, and Prob: Sunny 5 0.35714285714285715\n",
      "\t\tValue, Count, and Prob: Overcast 4 0.2857142857142857\n",
      "\tFeature: Temp\n",
      "\t\tValue, Count, and Prob: Mild 6 0.42857142857142855\n",
      "\t\tValue, Count, and Prob: Hot 4 0.2857142857142857\n",
      "\t\tValue, Count, and Prob: Cool 4 0.2857142857142857\n",
      "\tFeature: Humidity\n",
      "\t\tValue, Count, and Prob: High 7 0.5\n",
      "\t\tValue, Count, and Prob: Normal 7 0.5\n",
      "\tFeature: Windy\n",
      "\t\tValue, Count, and Prob: f 8 0.5714285714285714\n",
      "\t\tValue, Count, and Prob: t 6 0.42857142857142855\n",
      "\n",
      "Predictions:\n",
      "Train Accuracy: 0.9285714285714286\n",
      "\n",
      "Predictions:\n",
      "Query 1:- [['Rainy' 'Mild' 'Normal' 't']] ---> ['yes']\n",
      "\n",
      "Predictions:\n",
      "Query 2:- [['Overcast' 'Cool' 'Normal' 't']] ---> ['yes']\n",
      "\n",
      "Predictions:\n",
      "Query 3:- [['Sunny' 'Hot' 'High' 't']] ---> ['no']\n"
     ]
    }
   ],
   "source": [
    "#Split fearures and target\n",
    "X,y  = pre_processing(df)\n",
    "\n",
    "nb_clf = NaiveBayes()\n",
    "nb_clf.fit(X, y)\n",
    "\n",
    "print(\"Train Accuracy: {}\".format(accuracy_score(y, nb_clf.predict(X))))\n",
    "\n",
    "#Query 1:\n",
    "query = np.array([['Rainy','Mild', 'Normal', 't']])\n",
    "print(\"Query 1:- {} ---> {}\".format(query, nb_clf.predict(query)))\n",
    "\n",
    "#Query 2:\n",
    "query = np.array([['Overcast','Cool', 'Normal', 't']])\n",
    "print(\"Query 2:- {} ---> {}\".format(query, nb_clf.predict(query)))\n",
    "\n",
    "#Query 3:\n",
    "query = np.array([['Sunny','Hot', 'High', 't']])\n",
    "print(\"Query 3:- {} ---> {}\".format(query, nb_clf.predict(query)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes Notes\n",
    "\n",
    "We can see here, Bayes works totally differently from a logistic regression, even though it performs the same work. \n",
    "\n",
    "There are a few stipulations to using Naive Bayes, and a few varieties made to deal with scenarios that don't meet those stipulations:\n",
    "<ul>\n",
    "<li> Naive Bayes only works with categorical features. \n",
    "    <ul>\n",
    "    <li> Other versions of Bayes, such as Gaussian Bayes, allow numerical features to be used. For the Gaussian version, the probabilities are basically changed from the counting we did here, to probability estimates from a normal distribution. \n",
    "    </ul>\n",
    "<li> Normalization isn't relevant to Naive Bayes. \n",
    "<li> Encoding categorical varaibles isn't required. \n",
    "    <ul>\n",
    "    <li><b>Note:</b> this is generally true for the algorithm itself, but implementations of NB that you <b><i>might</i></b> use may require numerical inputs. That's a choice whoever made the library made in the design, NB handles categorical strings fine by default. \n",
    "    <li> For example, the sklearn implementation requires numerical encoding to work. \n",
    "    </ul>\n",
    "<li> Naive Bayes makes an assumption of independance between each feature, or that one feature's value does not impact another feature. This assumption is often not totally true in the real world (e.g. sunny and hot may tend to come together). The more independent the varaibles are from each other, the more reliable the results will be. \n",
    "<li> Naive Bayes can produce multinomial predictions (predicting between more than 2 classes) very easily. Our model above does it by default - each outcome has a probability of occuring, and the most likely one wins. \n",
    "    <ul>\n",
    "    <li> We will look into multiple class predictions more in the ML class, they are not always as simple as they are with Bayes. \n",
    "    <li> Each outcome is basically one row of a Bayes table, and we can handle 3+ with no real changes. \n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "### Bayes Uses and Benefits\n",
    "\n",
    "Bayes models are often used in things like spam detection. Naive Bayes can handle text inputs, and it is very fast to calculate, so that is an ideal scenario for the strength of the algorithm. It is also commonly used in recommendation systems, predicting if someone will like something, as well as sentiment analysis, identifying if text is positive or negative. Some other high points of the Naive Bayes classifier are:\n",
    "<ul>\n",
    "<li> The training datatset can be relatively small, so in cases where training data is limited, it may be a strong performer. \n",
    "<li> Multiple class predictions can be made with no real adaptations. Other models often require extra work to generate predictions for more than two outcome classes. \n",
    "<li> Bayes is also very simple and transparent, we can see exactly how decisions are made by the algorithm. This is also true for the regression algorithms we looked at, but it is not universal. \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Model - Realistic Example\n",
    "\n",
    "We are predicting the last column, the model. We have multiple classes for our output, and a bunch of categorical inputs. \n",
    "\n",
    "#### Data Prep\n",
    "\n",
    "The data has two things, the make and gear_box, that are categorical values, represented by numbers. We know this is fine, but we do need to check the data type and make sure that this is somehting that python will treat as a categorical value when processed. The most simple way to address that is to just make them strings, which I did below. There's probably several things you could do to these values to make them work, it really doesn't matter much - making it a string will tell python to treat it like other strings, which gets the job done. \n",
    "\n",
    "I've also taken a sample, the dataset is large and can take a bit to process. Comment this line out to process it all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_cluster</th>\n",
       "      <th>make</th>\n",
       "      <th>segment</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>is_esc</th>\n",
       "      <th>is_adjustable_steering</th>\n",
       "      <th>is_tpms</th>\n",
       "      <th>is_parking_sensors</th>\n",
       "      <th>is_parking_camera</th>\n",
       "      <th>rear_brakes_type</th>\n",
       "      <th>...</th>\n",
       "      <th>is_rear_window_defogger</th>\n",
       "      <th>is_brake_assist</th>\n",
       "      <th>is_power_door_locks</th>\n",
       "      <th>is_central_locking</th>\n",
       "      <th>is_power_steering</th>\n",
       "      <th>is_driver_seat_height_adjustable</th>\n",
       "      <th>is_day_night_rear_view_mirror</th>\n",
       "      <th>is_ecw</th>\n",
       "      <th>is_speed_alert</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21211</th>\n",
       "      <td>C8</td>\n",
       "      <td>1</td>\n",
       "      <td>B1</td>\n",
       "      <td>CNG</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Drum</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>M8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38111</th>\n",
       "      <td>C12</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>CNG</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Drum</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5549</th>\n",
       "      <td>C5</td>\n",
       "      <td>1</td>\n",
       "      <td>B2</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Drum</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>M6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5199</th>\n",
       "      <td>C8</td>\n",
       "      <td>1</td>\n",
       "      <td>B1</td>\n",
       "      <td>CNG</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Drum</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>M8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26260</th>\n",
       "      <td>C15</td>\n",
       "      <td>3</td>\n",
       "      <td>C2</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Disc</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>M4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      area_cluster make segment fuel_type is_esc is_adjustable_steering  \\\n",
       "21211           C8    1      B1       CNG     No                     No   \n",
       "38111          C12    1       A       CNG     No                     No   \n",
       "5549            C5    1      B2    Petrol     No                    Yes   \n",
       "5199            C8    1      B1       CNG     No                     No   \n",
       "26260          C15    3      C2    Diesel    Yes                    Yes   \n",
       "\n",
       "      is_tpms is_parking_sensors is_parking_camera rear_brakes_type  ...  \\\n",
       "21211      No                Yes                No             Drum  ...   \n",
       "38111      No                Yes                No             Drum  ...   \n",
       "5549       No                Yes                No             Drum  ...   \n",
       "5199       No                Yes                No             Drum  ...   \n",
       "26260     Yes                Yes               Yes             Disc  ...   \n",
       "\n",
       "      is_rear_window_defogger is_brake_assist is_power_door_locks  \\\n",
       "21211                      No              No                 Yes   \n",
       "38111                      No              No                  No   \n",
       "5549                       No             Yes                 Yes   \n",
       "5199                       No              No                 Yes   \n",
       "26260                     Yes             Yes                 Yes   \n",
       "\n",
       "      is_central_locking is_power_steering is_driver_seat_height_adjustable  \\\n",
       "21211                Yes               Yes                               No   \n",
       "38111                 No               Yes                               No   \n",
       "5549                 Yes               Yes                              Yes   \n",
       "5199                 Yes               Yes                               No   \n",
       "26260                Yes               Yes                              Yes   \n",
       "\n",
       "      is_day_night_rear_view_mirror is_ecw is_speed_alert model  \n",
       "21211                            No    Yes            Yes    M8  \n",
       "38111                            No     No            Yes    M1  \n",
       "5549                            Yes    Yes            Yes    M6  \n",
       "5199                             No    Yes            Yes    M8  \n",
       "26260                            No    Yes            Yes    M4  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"data/bayes_multi.csv\")\n",
    "df2[[\"make\", \"gear_box\"]] = df2[[\"make\", \"gear_box\"]].astype(\"string\")\n",
    "df2 = df2.sample(10000, random_state=42)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check the Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 21211 to 19754\n",
      "Data columns (total 26 columns):\n",
      " #   Column                            Non-Null Count  Dtype \n",
      "---  ------                            --------------  ----- \n",
      " 0   area_cluster                      10000 non-null  object\n",
      " 1   make                              10000 non-null  string\n",
      " 2   segment                           10000 non-null  object\n",
      " 3   fuel_type                         10000 non-null  object\n",
      " 4   is_esc                            10000 non-null  object\n",
      " 5   is_adjustable_steering            10000 non-null  object\n",
      " 6   is_tpms                           10000 non-null  object\n",
      " 7   is_parking_sensors                10000 non-null  object\n",
      " 8   is_parking_camera                 10000 non-null  object\n",
      " 9   rear_brakes_type                  10000 non-null  object\n",
      " 10  transmission_type                 10000 non-null  object\n",
      " 11  gear_box                          10000 non-null  string\n",
      " 12  steering_type                     10000 non-null  object\n",
      " 13  is_front_fog_lights               10000 non-null  object\n",
      " 14  is_rear_window_wiper              10000 non-null  object\n",
      " 15  is_rear_window_washer             10000 non-null  object\n",
      " 16  is_rear_window_defogger           10000 non-null  object\n",
      " 17  is_brake_assist                   10000 non-null  object\n",
      " 18  is_power_door_locks               10000 non-null  object\n",
      " 19  is_central_locking                10000 non-null  object\n",
      " 20  is_power_steering                 10000 non-null  object\n",
      " 21  is_driver_seat_height_adjustable  10000 non-null  object\n",
      " 22  is_day_night_rear_view_mirror     10000 non-null  object\n",
      " 23  is_ecw                            10000 non-null  object\n",
      " 24  is_speed_alert                    10000 non-null  object\n",
      " 25  model                             10000 non-null  object\n",
      "dtypes: object(24), string(2)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check For Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "area_cluster                        0\n",
       "make                                0\n",
       "segment                             0\n",
       "fuel_type                           0\n",
       "is_esc                              0\n",
       "is_adjustable_steering              0\n",
       "is_tpms                             0\n",
       "is_parking_sensors                  0\n",
       "is_parking_camera                   0\n",
       "rear_brakes_type                    0\n",
       "transmission_type                   0\n",
       "gear_box                            0\n",
       "steering_type                       0\n",
       "is_front_fog_lights                 0\n",
       "is_rear_window_wiper                0\n",
       "is_rear_window_washer               0\n",
       "is_rear_window_defogger             0\n",
       "is_brake_assist                     0\n",
       "is_power_door_locks                 0\n",
       "is_central_locking                  0\n",
       "is_power_steering                   0\n",
       "is_driver_seat_height_adjustable    0\n",
       "is_day_night_rear_view_mirror       0\n",
       "is_ecw                              0\n",
       "is_speed_alert                      0\n",
       "model                               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Predict\n",
    "\n",
    "We can use our model almost exactly the same as we use any others. We can mix it in here with the train-test split, and the accuracy score functions from sklearn. The interchangeability that we have with the sklearn stuff carries through most areas, and makes it convinient for us to try new things without needing to learn a lot of specifics about each possible function. \n",
    "\n",
    "#### Important Notes for Execution:\n",
    "\n",
    "For this one we have a few things to watch out for when making predictions. The main thing is that we don't have anything in place to handle the zero probability problem. To avoid this, I tested it and set the random state arguments in the random bits - that should ensure that the randomness is always the same, so if it worked for me once, you should get the same splits. We also have a large dataset and a small test split, so the odds of getting one of those is pretty low. If you dropped the random state argument, it <i><b>could</i></b> happen, and you could get an error. The probability is low and it is random, so the odds are it will still work. At any point in time it might fail though. \n",
    "\n",
    "I've also added a stratify argument to the train-test split, that tells it to make sure that each class in y2, the target varible, is represented in each of the training and testing dataset in roughly equal proportions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outcome Priors:\n",
      "M1 2282\n",
      "M10 161\n",
      "M11 59\n",
      "M2 159\n",
      "M3 398\n",
      "M4 2216\n",
      "M5 231\n",
      "M6 2085\n",
      "M7 412\n",
      "M8 669\n",
      "M9 328\n",
      "\n",
      "Likelihoods:\n",
      "\tLikelihoods for: area_cluster\n",
      "\t\tOutcome: M1 2282\n",
      "\t\t\tFeature Value, Count, and Prob: C3 490 0.2147239263803681\n",
      "\t\t\tFeature Value, Count, and Prob: C5 403 0.1765994741454864\n",
      "\t\t\tFeature Value, Count, and Prob: C2 265 0.1161262050832603\n",
      "\t\t\tFeature Value, Count, and Prob: C10 196 0.08588957055214724\n",
      "\t\t\tFeature Value, Count, and Prob: C9 129 0.05652936021034181\n",
      "\t\t\tFeature Value, Count, and Prob: C1 123 0.05390008764241893\n",
      "\t\t\tFeature Value, Count, and Prob: C7 95 0.04163014899211218\n",
      "\t\t\tFeature Value, Count, and Prob: C13 83 0.036371603856266435\n",
      "\t\t\tFeature Value, Count, and Prob: C8 79 0.034618755477651184\n",
      "\t\t\tFeature Value, Count, and Prob: C4 49 0.02147239263803681\n",
      "\t\t\tFeature Value, Count, and Prob: C11 44 0.019281332164767746\n",
      "\t\t\tFeature Value, Count, and Prob: C16 44 0.019281332164767746\n",
      "\t\t\tFeature Value, Count, and Prob: C14 42 0.018404907975460124\n",
      "\t\t\tFeature Value, Count, and Prob: C12 40 0.017528483786152498\n",
      "\t\t\tFeature Value, Count, and Prob: C17 37 0.01621384750219106\n",
      "\t\t\tFeature Value, Count, and Prob: C6 37 0.01621384750219106\n",
      "\t\t\tFeature Value, Count, and Prob: C15 34 0.014899211218229623\n",
      "\t\t\tFeature Value, Count, and Prob: C18 28 0.012269938650306749\n",
      "\t\t\tFeature Value, Count, and Prob: C21 24 0.010517090271691499\n",
      "\t\t\tFeature Value, Count, and Prob: C19 23 0.010078878177037686\n",
      "\t\t\tFeature Value, Count, and Prob: C20 10 0.0043821209465381246\n",
      "\t\t\tFeature Value, Count, and Prob: C22 7 0.003067484662576687\n",
      "\t\tOutcome: M10 161\n",
      "\t\t\tFeature Value, Count, and Prob: C8 46 0.2857142857142857\n",
      "\t\t\tFeature Value, Count, and Prob: C2 24 0.14906832298136646\n",
      "\t\t\tFeature Value, Count, and Prob: C5 20 0.12422360248447205\n",
      "\t\t\tFeature Value, Count, and Prob: C3 12 0.07453416149068323\n",
      "\t\t\tFeature Value, Count, and Prob: C10 11 0.06832298136645963\n",
      "\t\t\tFeature Value, Count, and Prob: C14 8 0.049689440993788817\n",
      "\t\t\tFeature Value, Count, and Prob: C7 5 0.031055900621118012\n",
      "\t\t\tFeature Value, Count, and Prob: C19 5 0.031055900621118012\n",
      "\t\t\tFeature Value, Count, and Prob: C13 5 0.031055900621118012\n",
      "\t\t\tFeature Value, Count, and Prob: C12 4 0.024844720496894408\n",
      "\t\t\tFeature Value, Count, and Prob: C1 4 0.024844720496894408\n",
      "\t\t\tFeature Value, Count, and Prob: C11 4 0.024844720496894408\n",
      "\t\t\tFeature Value, Count, and Prob: C9 4 0.024844720496894408\n",
      "\t\t\tFeature Value, Count, and Prob: C21 3 0.018633540372670808\n",
      "\t\t\tFeature Value, Count, and Prob: C6 3 0.018633540372670808\n",
      "\t\t\tFeature Value, Count, and Prob: C15 2 0.012422360248447204\n",
      "\t\t\tFeature Value, Count, and Prob: C16 1 0.006211180124223602\n",
      "\t\tOutcome: M11 59\n",
      "\t\t\tFeature Value, Count, and Prob: C8 11 0.1864406779661017\n",
      "\t\t\tFeature Value, Count, and Prob: C5 11 0.1864406779661017\n",
      "\t\t\tFeature Value, Count, and Prob: C2 6 0.1016949152542373\n",
      "\t\t\tFeature Value, Count, and Prob: C9 5 0.0847457627118644\n",
      "\t\t\tFeature Value, Count, and Prob: C10 4 0.06779661016949153\n",
      "\t\t\tFeature Value, Count, and Prob: C14 4 0.06779661016949153\n",
      "\t\t\tFeature Value, Count, and Prob: C13 4 0.06779661016949153\n",
      "\t\t\tFeature Value, Count, and Prob: C3 3 0.05084745762711865\n",
      "\t\t\tFeature Value, Count, and Prob: C4 3 0.05084745762711865\n",
      "\t\t\tFeature Value, Count, and Prob: C12 2 0.03389830508474576\n",
      "\t\t\tFeature Value, Count, and Prob: C1 2 0.03389830508474576\n",
      "\t\t\tFeature Value, Count, and Prob: C11 2 0.03389830508474576\n",
      "\t\t\tFeature Value, Count, and Prob: C16 1 0.01694915254237288\n",
      "\t\t\tFeature Value, Count, and Prob: C17 1 0.01694915254237288\n",
      "\t\tOutcome: M2 159\n",
      "\t\t\tFeature Value, Count, and Prob: C8 40 0.25157232704402516\n",
      "\t\t\tFeature Value, Count, and Prob: C5 21 0.1320754716981132\n",
      "\t\t\tFeature Value, Count, and Prob: C2 20 0.12578616352201258\n",
      "\t\t\tFeature Value, Count, and Prob: C3 16 0.10062893081761007\n",
      "\t\t\tFeature Value, Count, and Prob: C14 14 0.0880503144654088\n",
      "\t\t\tFeature Value, Count, and Prob: C13 9 0.05660377358490566\n",
      "\t\t\tFeature Value, Count, and Prob: C9 6 0.03773584905660377\n",
      "\t\t\tFeature Value, Count, and Prob: C1 5 0.031446540880503145\n",
      "\t\t\tFeature Value, Count, and Prob: C6 4 0.025157232704402517\n",
      "\t\t\tFeature Value, Count, and Prob: C7 4 0.025157232704402517\n",
      "\t\t\tFeature Value, Count, and Prob: C12 4 0.025157232704402517\n",
      "\t\t\tFeature Value, Count, and Prob: C10 3 0.018867924528301886\n",
      "\t\t\tFeature Value, Count, and Prob: C19 3 0.018867924528301886\n",
      "\t\t\tFeature Value, Count, and Prob: C17 2 0.012578616352201259\n",
      "\t\t\tFeature Value, Count, and Prob: C15 2 0.012578616352201259\n",
      "\t\t\tFeature Value, Count, and Prob: C21 2 0.012578616352201259\n",
      "\t\t\tFeature Value, Count, and Prob: C4 2 0.012578616352201259\n",
      "\t\t\tFeature Value, Count, and Prob: C16 1 0.006289308176100629\n",
      "\t\t\tFeature Value, Count, and Prob: C18 1 0.006289308176100629\n",
      "\t\tOutcome: M3 398\n",
      "\t\t\tFeature Value, Count, and Prob: C8 85 0.2135678391959799\n",
      "\t\t\tFeature Value, Count, and Prob: C5 58 0.1457286432160804\n",
      "\t\t\tFeature Value, Count, and Prob: C2 58 0.1457286432160804\n",
      "\t\t\tFeature Value, Count, and Prob: C14 36 0.09045226130653267\n",
      "\t\t\tFeature Value, Count, and Prob: C13 29 0.0728643216080402\n",
      "\t\t\tFeature Value, Count, and Prob: C10 24 0.06030150753768844\n",
      "\t\t\tFeature Value, Count, and Prob: C3 23 0.05778894472361809\n",
      "\t\t\tFeature Value, Count, and Prob: C9 19 0.04773869346733668\n",
      "\t\t\tFeature Value, Count, and Prob: C12 16 0.04020100502512563\n",
      "\t\t\tFeature Value, Count, and Prob: C7 9 0.022613065326633167\n",
      "\t\t\tFeature Value, Count, and Prob: C17 7 0.017587939698492462\n",
      "\t\t\tFeature Value, Count, and Prob: C1 7 0.017587939698492462\n",
      "\t\t\tFeature Value, Count, and Prob: C21 5 0.01256281407035176\n",
      "\t\t\tFeature Value, Count, and Prob: C15 5 0.01256281407035176\n",
      "\t\t\tFeature Value, Count, and Prob: C22 4 0.010050251256281407\n",
      "\t\t\tFeature Value, Count, and Prob: C11 4 0.010050251256281407\n",
      "\t\t\tFeature Value, Count, and Prob: C4 3 0.007537688442211055\n",
      "\t\t\tFeature Value, Count, and Prob: C20 2 0.005025125628140704\n",
      "\t\t\tFeature Value, Count, and Prob: C6 2 0.005025125628140704\n",
      "\t\t\tFeature Value, Count, and Prob: C16 1 0.002512562814070352\n",
      "\t\t\tFeature Value, Count, and Prob: C19 1 0.002512562814070352\n",
      "\t\tOutcome: M4 2216\n",
      "\t\t\tFeature Value, Count, and Prob: C8 739 0.3334837545126354\n",
      "\t\t\tFeature Value, Count, and Prob: C2 302 0.13628158844765342\n",
      "\t\t\tFeature Value, Count, and Prob: C5 206 0.09296028880866426\n",
      "\t\t\tFeature Value, Count, and Prob: C14 160 0.07220216606498195\n",
      "\t\t\tFeature Value, Count, and Prob: C13 158 0.07129963898916968\n",
      "\t\t\tFeature Value, Count, and Prob: C3 134 0.06046931407942238\n",
      "\t\t\tFeature Value, Count, and Prob: C10 93 0.04196750902527076\n",
      "\t\t\tFeature Value, Count, and Prob: C7 80 0.036101083032490974\n",
      "\t\t\tFeature Value, Count, and Prob: C9 79 0.03564981949458484\n",
      "\t\t\tFeature Value, Count, and Prob: C12 59 0.026624548736462094\n",
      "\t\t\tFeature Value, Count, and Prob: C19 46 0.02075812274368231\n",
      "\t\t\tFeature Value, Count, and Prob: C15 34 0.015342960288808664\n",
      "\t\t\tFeature Value, Count, and Prob: C6 29 0.013086642599277979\n",
      "\t\t\tFeature Value, Count, and Prob: C1 25 0.01128158844765343\n",
      "\t\t\tFeature Value, Count, and Prob: C11 24 0.010830324909747292\n",
      "\t\t\tFeature Value, Count, and Prob: C4 21 0.00947653429602888\n",
      "\t\t\tFeature Value, Count, and Prob: C21 8 0.0036101083032490976\n",
      "\t\t\tFeature Value, Count, and Prob: C16 6 0.002707581227436823\n",
      "\t\t\tFeature Value, Count, and Prob: C18 4 0.0018050541516245488\n",
      "\t\t\tFeature Value, Count, and Prob: C17 3 0.0013537906137184115\n",
      "\t\t\tFeature Value, Count, and Prob: C20 3 0.0013537906137184115\n",
      "\t\t\tFeature Value, Count, and Prob: C22 3 0.0013537906137184115\n",
      "\t\tOutcome: M5 231\n",
      "\t\t\tFeature Value, Count, and Prob: C8 57 0.24675324675324675\n",
      "\t\t\tFeature Value, Count, and Prob: C2 28 0.12121212121212122\n",
      "\t\t\tFeature Value, Count, and Prob: C5 28 0.12121212121212122\n",
      "\t\t\tFeature Value, Count, and Prob: C14 23 0.09956709956709957\n",
      "\t\t\tFeature Value, Count, and Prob: C10 15 0.06493506493506493\n",
      "\t\t\tFeature Value, Count, and Prob: C3 14 0.06060606060606061\n",
      "\t\t\tFeature Value, Count, and Prob: C7 12 0.05194805194805195\n",
      "\t\t\tFeature Value, Count, and Prob: C13 12 0.05194805194805195\n",
      "\t\t\tFeature Value, Count, and Prob: C9 8 0.03463203463203463\n",
      "\t\t\tFeature Value, Count, and Prob: C12 6 0.025974025974025976\n",
      "\t\t\tFeature Value, Count, and Prob: C6 5 0.021645021645021644\n",
      "\t\t\tFeature Value, Count, and Prob: C1 5 0.021645021645021644\n",
      "\t\t\tFeature Value, Count, and Prob: C19 4 0.017316017316017316\n",
      "\t\t\tFeature Value, Count, and Prob: C15 4 0.017316017316017316\n",
      "\t\t\tFeature Value, Count, and Prob: C4 4 0.017316017316017316\n",
      "\t\t\tFeature Value, Count, and Prob: C20 2 0.008658008658008658\n",
      "\t\t\tFeature Value, Count, and Prob: C17 1 0.004329004329004329\n",
      "\t\t\tFeature Value, Count, and Prob: C21 1 0.004329004329004329\n",
      "\t\t\tFeature Value, Count, and Prob: C11 1 0.004329004329004329\n",
      "\t\t\tFeature Value, Count, and Prob: C22 1 0.004329004329004329\n",
      "\t\tOutcome: M6 2085\n",
      "\t\t\tFeature Value, Count, and Prob: C8 717 0.34388489208633094\n",
      "\t\t\tFeature Value, Count, and Prob: C2 225 0.1079136690647482\n",
      "\t\t\tFeature Value, Count, and Prob: C5 194 0.09304556354916067\n",
      "\t\t\tFeature Value, Count, and Prob: C14 187 0.08968824940047962\n",
      "\t\t\tFeature Value, Count, and Prob: C13 118 0.056594724220623505\n",
      "\t\t\tFeature Value, Count, and Prob: C3 109 0.05227817745803357\n",
      "\t\t\tFeature Value, Count, and Prob: C10 80 0.03836930455635491\n",
      "\t\t\tFeature Value, Count, and Prob: C9 77 0.036930455635491605\n",
      "\t\t\tFeature Value, Count, and Prob: C7 66 0.031654676258992806\n",
      "\t\t\tFeature Value, Count, and Prob: C12 65 0.03117505995203837\n",
      "\t\t\tFeature Value, Count, and Prob: C11 50 0.023980815347721823\n",
      "\t\t\tFeature Value, Count, and Prob: C19 44 0.021103117505995205\n",
      "\t\t\tFeature Value, Count, and Prob: C6 34 0.01630695443645084\n",
      "\t\t\tFeature Value, Count, and Prob: C1 34 0.01630695443645084\n",
      "\t\t\tFeature Value, Count, and Prob: C15 26 0.012470023980815348\n",
      "\t\t\tFeature Value, Count, and Prob: C21 18 0.008633093525179856\n",
      "\t\t\tFeature Value, Count, and Prob: C4 10 0.004796163069544364\n",
      "\t\t\tFeature Value, Count, and Prob: C17 9 0.004316546762589928\n",
      "\t\t\tFeature Value, Count, and Prob: C16 7 0.003357314148681055\n",
      "\t\t\tFeature Value, Count, and Prob: C20 6 0.0028776978417266188\n",
      "\t\t\tFeature Value, Count, and Prob: C22 6 0.0028776978417266188\n",
      "\t\t\tFeature Value, Count, and Prob: C18 3 0.0014388489208633094\n",
      "\t\tOutcome: M7 412\n",
      "\t\t\tFeature Value, Count, and Prob: C8 112 0.27184466019417475\n",
      "\t\t\tFeature Value, Count, and Prob: C2 56 0.13592233009708737\n",
      "\t\t\tFeature Value, Count, and Prob: C5 42 0.10194174757281553\n",
      "\t\t\tFeature Value, Count, and Prob: C14 28 0.06796116504854369\n",
      "\t\t\tFeature Value, Count, and Prob: C3 26 0.06310679611650485\n",
      "\t\t\tFeature Value, Count, and Prob: C9 25 0.06067961165048544\n",
      "\t\t\tFeature Value, Count, and Prob: C13 22 0.05339805825242718\n",
      "\t\t\tFeature Value, Count, and Prob: C7 22 0.05339805825242718\n",
      "\t\t\tFeature Value, Count, and Prob: C10 19 0.04611650485436893\n",
      "\t\t\tFeature Value, Count, and Prob: C11 14 0.03398058252427184\n",
      "\t\t\tFeature Value, Count, and Prob: C12 10 0.024271844660194174\n",
      "\t\t\tFeature Value, Count, and Prob: C6 8 0.019417475728155338\n",
      "\t\t\tFeature Value, Count, and Prob: C1 8 0.019417475728155338\n",
      "\t\t\tFeature Value, Count, and Prob: C21 6 0.014563106796116505\n",
      "\t\t\tFeature Value, Count, and Prob: C19 5 0.012135922330097087\n",
      "\t\t\tFeature Value, Count, and Prob: C15 3 0.007281553398058253\n",
      "\t\t\tFeature Value, Count, and Prob: C4 2 0.0048543689320388345\n",
      "\t\t\tFeature Value, Count, and Prob: C22 2 0.0048543689320388345\n",
      "\t\t\tFeature Value, Count, and Prob: C20 2 0.0048543689320388345\n",
      "\t\tOutcome: M8 669\n",
      "\t\t\tFeature Value, Count, and Prob: C8 187 0.2795216741405082\n",
      "\t\t\tFeature Value, Count, and Prob: C5 96 0.14349775784753363\n",
      "\t\t\tFeature Value, Count, and Prob: C2 94 0.14050822122571002\n",
      "\t\t\tFeature Value, Count, and Prob: C14 57 0.08520179372197309\n",
      "\t\t\tFeature Value, Count, and Prob: C3 43 0.06427503736920777\n",
      "\t\t\tFeature Value, Count, and Prob: C13 32 0.04783258594917788\n",
      "\t\t\tFeature Value, Count, and Prob: C7 28 0.04185351270553064\n",
      "\t\t\tFeature Value, Count, and Prob: C10 25 0.03736920777279522\n",
      "\t\t\tFeature Value, Count, and Prob: C9 25 0.03736920777279522\n",
      "\t\t\tFeature Value, Count, and Prob: C12 19 0.028400597907324365\n",
      "\t\t\tFeature Value, Count, and Prob: C1 13 0.01943198804185351\n",
      "\t\t\tFeature Value, Count, and Prob: C11 9 0.013452914798206279\n",
      "\t\t\tFeature Value, Count, and Prob: C6 7 0.01046337817638266\n",
      "\t\t\tFeature Value, Count, and Prob: C16 7 0.01046337817638266\n",
      "\t\t\tFeature Value, Count, and Prob: C15 5 0.007473841554559043\n",
      "\t\t\tFeature Value, Count, and Prob: C4 5 0.007473841554559043\n",
      "\t\t\tFeature Value, Count, and Prob: C17 5 0.007473841554559043\n",
      "\t\t\tFeature Value, Count, and Prob: C19 4 0.005979073243647235\n",
      "\t\t\tFeature Value, Count, and Prob: C22 3 0.004484304932735426\n",
      "\t\t\tFeature Value, Count, and Prob: C21 2 0.0029895366218236174\n",
      "\t\t\tFeature Value, Count, and Prob: C18 2 0.0029895366218236174\n",
      "\t\t\tFeature Value, Count, and Prob: C20 1 0.0014947683109118087\n",
      "\t\tOutcome: M9 328\n",
      "\t\t\tFeature Value, Count, and Prob: C8 68 0.2073170731707317\n",
      "\t\t\tFeature Value, Count, and Prob: C5 38 0.11585365853658537\n",
      "\t\t\tFeature Value, Count, and Prob: C14 33 0.10060975609756098\n",
      "\t\t\tFeature Value, Count, and Prob: C2 32 0.0975609756097561\n",
      "\t\t\tFeature Value, Count, and Prob: C3 29 0.08841463414634146\n",
      "\t\t\tFeature Value, Count, and Prob: C9 23 0.0701219512195122\n",
      "\t\t\tFeature Value, Count, and Prob: C7 20 0.06097560975609756\n",
      "\t\t\tFeature Value, Count, and Prob: C10 19 0.057926829268292686\n",
      "\t\t\tFeature Value, Count, and Prob: C13 17 0.051829268292682924\n",
      "\t\t\tFeature Value, Count, and Prob: C11 13 0.039634146341463415\n",
      "\t\t\tFeature Value, Count, and Prob: C12 8 0.024390243902439025\n",
      "\t\t\tFeature Value, Count, and Prob: C15 6 0.018292682926829267\n",
      "\t\t\tFeature Value, Count, and Prob: C19 5 0.01524390243902439\n",
      "\t\t\tFeature Value, Count, and Prob: C1 4 0.012195121951219513\n",
      "\t\t\tFeature Value, Count, and Prob: C4 4 0.012195121951219513\n",
      "\t\t\tFeature Value, Count, and Prob: C21 3 0.009146341463414634\n",
      "\t\t\tFeature Value, Count, and Prob: C6 2 0.006097560975609756\n",
      "\t\t\tFeature Value, Count, and Prob: C22 2 0.006097560975609756\n",
      "\t\t\tFeature Value, Count, and Prob: C20 1 0.003048780487804878\n",
      "\t\t\tFeature Value, Count, and Prob: C16 1 0.003048780487804878\n",
      "\tLikelihoods for: make\n",
      "\t\tOutcome: M1 2282\n",
      "\t\t\tFeature Value, Count, and Prob: 1 2282 1.0\n",
      "\t\tOutcome: M10 161\n",
      "\t\t\tFeature Value, Count, and Prob: 1 161 1.0\n",
      "\t\tOutcome: M11 59\n",
      "\t\t\tFeature Value, Count, and Prob: 4 59 1.0\n",
      "\t\tOutcome: M2 159\n",
      "\t\t\tFeature Value, Count, and Prob: 1 159 1.0\n",
      "\t\tOutcome: M3 398\n",
      "\t\t\tFeature Value, Count, and Prob: 2 398 1.0\n",
      "\t\tOutcome: M4 2216\n",
      "\t\t\tFeature Value, Count, and Prob: 3 2216 1.0\n",
      "\t\tOutcome: M5 231\n",
      "\t\t\tFeature Value, Count, and Prob: 4 231 1.0\n",
      "\t\tOutcome: M6 2085\n",
      "\t\t\tFeature Value, Count, and Prob: 1 2085 1.0\n",
      "\t\tOutcome: M7 412\n",
      "\t\t\tFeature Value, Count, and Prob: 1 412 1.0\n",
      "\t\tOutcome: M8 669\n",
      "\t\t\tFeature Value, Count, and Prob: 1 669 1.0\n",
      "\t\tOutcome: M9 328\n",
      "\t\t\tFeature Value, Count, and Prob: 5 328 1.0\n",
      "\tLikelihoods for: segment\n",
      "\t\tOutcome: M1 2282\n",
      "\t\t\tFeature Value, Count, and Prob: A 2282 1.0\n",
      "\t\tOutcome: M10 161\n",
      "\t\t\tFeature Value, Count, and Prob: Utility 161 1.0\n",
      "\t\tOutcome: M11 59\n",
      "\t\t\tFeature Value, Count, and Prob: C1 59 1.0\n",
      "\t\tOutcome: M2 159\n",
      "\t\t\tFeature Value, Count, and Prob: C1 159 1.0\n",
      "\t\tOutcome: M3 398\n",
      "\t\t\tFeature Value, Count, and Prob: A 398 1.0\n",
      "\t\tOutcome: M4 2216\n",
      "\t\t\tFeature Value, Count, and Prob: C2 2216 1.0\n",
      "\t\tOutcome: M5 231\n",
      "\t\t\tFeature Value, Count, and Prob: B2 231 1.0\n",
      "\t\tOutcome: M6 2085\n",
      "\t\t\tFeature Value, Count, and Prob: B2 2085 1.0\n",
      "\t\tOutcome: M7 412\n",
      "\t\t\tFeature Value, Count, and Prob: B2 412 1.0\n",
      "\t\tOutcome: M8 669\n",
      "\t\t\tFeature Value, Count, and Prob: B1 669 1.0\n",
      "\t\tOutcome: M9 328\n",
      "\t\t\tFeature Value, Count, and Prob: C1 328 1.0\n",
      "\tLikelihoods for: fuel_type\n",
      "\t\tOutcome: M1 2282\n",
      "\t\t\tFeature Value, Count, and Prob: CNG 2282 1.0\n",
      "\t\tOutcome: M10 161\n",
      "\t\t\tFeature Value, Count, and Prob: CNG 161 1.0\n",
      "\t\tOutcome: M11 59\n",
      "\t\t\tFeature Value, Count, and Prob: Petrol 59 1.0\n",
      "\t\tOutcome: M2 159\n",
      "\t\t\tFeature Value, Count, and Prob: Petrol 159 1.0\n",
      "\t\tOutcome: M3 398\n",
      "\t\t\tFeature Value, Count, and Prob: Petrol 398 1.0\n",
      "\t\tOutcome: M4 2216\n",
      "\t\t\tFeature Value, Count, and Prob: Diesel 2216 1.0\n",
      "\t\tOutcome: M5 231\n",
      "\t\t\tFeature Value, Count, and Prob: Diesel 231 1.0\n",
      "\t\tOutcome: M6 2085\n",
      "\t\t\tFeature Value, Count, and Prob: Petrol 2085 1.0\n",
      "\t\tOutcome: M7 412\n",
      "\t\t\tFeature Value, Count, and Prob: Petrol 412 1.0\n",
      "\t\tOutcome: M8 669\n",
      "\t\t\tFeature Value, Count, and Prob: CNG 669 1.0\n",
      "\t\tOutcome: M9 328\n",
      "\t\t\tFeature Value, Count, and Prob: Diesel 328 1.0\n",
      "\tLikelihoods for: is_esc\n",
      "\t\tOutcome: M1 2282\n",
      "\t\t\tFeature Value, Count, and Prob: No 2282 1.0\n",
      "\t\tOutcome: M10 161\n",
      "\t\t\tFeature Value, Count, and Prob: No 161 1.0\n",
      "\t\tOutcome: M11 59\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 59 1.0\n",
      "\t\tOutcome: M2 159\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 159 1.0\n",
      "\t\tOutcome: M3 398\n",
      "\t\t\tFeature Value, Count, and Prob: No 398 1.0\n",
      "\t\tOutcome: M4 2216\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2216 1.0\n",
      "\t\tOutcome: M5 231\n",
      "\t\t\tFeature Value, Count, and Prob: No 231 1.0\n",
      "\t\tOutcome: M6 2085\n",
      "\t\t\tFeature Value, Count, and Prob: No 2085 1.0\n",
      "\t\tOutcome: M7 412\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 412 1.0\n",
      "\t\tOutcome: M8 669\n",
      "\t\t\tFeature Value, Count, and Prob: No 669 1.0\n",
      "\t\tOutcome: M9 328\n",
      "\t\t\tFeature Value, Count, and Prob: No 328 1.0\n",
      "\tLikelihoods for: is_adjustable_steering\n",
      "\t\tOutcome: M1 2282\n",
      "\t\t\tFeature Value, Count, and Prob: No 2282 1.0\n",
      "\t\tOutcome: M10 161\n",
      "\t\t\tFeature Value, Count, and Prob: No 161 1.0\n",
      "\t\tOutcome: M11 59\n",
      "\t\t\tFeature Value, Count, and Prob: No 59 1.0\n",
      "\t\tOutcome: M2 159\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 159 1.0\n",
      "\t\tOutcome: M3 398\n",
      "\t\t\tFeature Value, Count, and Prob: No 398 1.0\n",
      "\t\tOutcome: M4 2216\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2216 1.0\n",
      "\t\tOutcome: M5 231\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 231 1.0\n",
      "\t\tOutcome: M6 2085\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2085 1.0\n",
      "\t\tOutcome: M7 412\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 412 1.0\n",
      "\t\tOutcome: M8 669\n",
      "\t\t\tFeature Value, Count, and Prob: No 669 1.0\n",
      "\t\tOutcome: M9 328\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 328 1.0\n",
      "\tLikelihoods for: is_tpms\n",
      "\t\tOutcome: M1 2282\n",
      "\t\t\tFeature Value, Count, and Prob: No 2282 1.0\n",
      "\t\tOutcome: M10 161\n",
      "\t\t\tFeature Value, Count, and Prob: No 161 1.0\n",
      "\t\tOutcome: M11 59\n",
      "\t\t\tFeature Value, Count, and Prob: No 59 1.0\n",
      "\t\tOutcome: M2 159\n",
      "\t\t\tFeature Value, Count, and Prob: No 159 1.0\n",
      "\t\tOutcome: M3 398\n",
      "\t\t\tFeature Value, Count, and Prob: No 398 1.0\n",
      "\t\tOutcome: M4 2216\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2216 1.0\n",
      "\t\tOutcome: M5 231\n",
      "\t\t\tFeature Value, Count, and Prob: No 231 1.0\n",
      "\t\tOutcome: M6 2085\n",
      "\t\t\tFeature Value, Count, and Prob: No 2085 1.0\n",
      "\t\tOutcome: M7 412\n",
      "\t\t\tFeature Value, Count, and Prob: No 412 1.0\n",
      "\t\tOutcome: M8 669\n",
      "\t\t\tFeature Value, Count, and Prob: No 669 1.0\n",
      "\t\tOutcome: M9 328\n",
      "\t\t\tFeature Value, Count, and Prob: No 328 1.0\n",
      "\tLikelihoods for: is_parking_sensors\n",
      "\t\tOutcome: M1 2282\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2282 1.0\n",
      "\t\tOutcome: M10 161\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 161 1.0\n",
      "\t\tOutcome: M11 59\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 59 1.0\n",
      "\t\tOutcome: M2 159\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 159 1.0\n",
      "\t\tOutcome: M3 398\n",
      "\t\t\tFeature Value, Count, and Prob: No 398 1.0\n",
      "\t\tOutcome: M4 2216\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2216 1.0\n",
      "\t\tOutcome: M5 231\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 231 1.0\n",
      "\t\tOutcome: M6 2085\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2085 1.0\n",
      "\t\tOutcome: M7 412\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 412 1.0\n",
      "\t\tOutcome: M8 669\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 669 1.0\n",
      "\t\tOutcome: M9 328\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 328 1.0\n",
      "\tLikelihoods for: is_parking_camera\n",
      "\t\tOutcome: M1 2282\n",
      "\t\t\tFeature Value, Count, and Prob: No 2282 1.0\n",
      "\t\tOutcome: M10 161\n",
      "\t\t\tFeature Value, Count, and Prob: No 161 1.0\n",
      "\t\tOutcome: M11 59\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 59 1.0\n",
      "\t\tOutcome: M2 159\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 159 1.0\n",
      "\t\tOutcome: M3 398\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 398 1.0\n",
      "\t\tOutcome: M4 2216\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2216 1.0\n",
      "\t\tOutcome: M5 231\n",
      "\t\t\tFeature Value, Count, and Prob: No 231 1.0\n",
      "\t\tOutcome: M6 2085\n",
      "\t\t\tFeature Value, Count, and Prob: No 2085 1.0\n",
      "\t\tOutcome: M7 412\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 412 1.0\n",
      "\t\tOutcome: M8 669\n",
      "\t\t\tFeature Value, Count, and Prob: No 669 1.0\n",
      "\t\tOutcome: M9 328\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 328 1.0\n",
      "\tLikelihoods for: rear_brakes_type\n",
      "\t\tOutcome: M1 2282\n",
      "\t\t\tFeature Value, Count, and Prob: Drum 2282 1.0\n",
      "\t\tOutcome: M10 161\n",
      "\t\t\tFeature Value, Count, and Prob: Drum 161 1.0\n",
      "\t\tOutcome: M11 59\n",
      "\t\t\tFeature Value, Count, and Prob: Drum 59 1.0\n",
      "\t\tOutcome: M2 159\n",
      "\t\t\tFeature Value, Count, and Prob: Drum 159 1.0\n",
      "\t\tOutcome: M3 398\n",
      "\t\t\tFeature Value, Count, and Prob: Drum 398 1.0\n",
      "\t\tOutcome: M4 2216\n",
      "\t\t\tFeature Value, Count, and Prob: Disc 2216 1.0\n",
      "\t\tOutcome: M5 231\n",
      "\t\t\tFeature Value, Count, and Prob: Drum 231 1.0\n",
      "\t\tOutcome: M6 2085\n",
      "\t\t\tFeature Value, Count, and Prob: Drum 2085 1.0\n",
      "\t\tOutcome: M7 412\n",
      "\t\t\tFeature Value, Count, and Prob: Drum 412 1.0\n",
      "\t\tOutcome: M8 669\n",
      "\t\t\tFeature Value, Count, and Prob: Drum 669 1.0\n",
      "\t\tOutcome: M9 328\n",
      "\t\t\tFeature Value, Count, and Prob: Drum 328 1.0\n",
      "\tLikelihoods for: transmission_type\n",
      "\t\tOutcome: M1 2282\n",
      "\t\t\tFeature Value, Count, and Prob: Manual 2282 1.0\n",
      "\t\tOutcome: M10 161\n",
      "\t\t\tFeature Value, Count, and Prob: Manual 161 1.0\n",
      "\t\tOutcome: M11 59\n",
      "\t\t\tFeature Value, Count, and Prob: Manual 59 1.0\n",
      "\t\tOutcome: M2 159\n",
      "\t\t\tFeature Value, Count, and Prob: Automatic 159 1.0\n",
      "\t\tOutcome: M3 398\n",
      "\t\t\tFeature Value, Count, and Prob: Automatic 398 1.0\n",
      "\t\tOutcome: M4 2216\n",
      "\t\t\tFeature Value, Count, and Prob: Automatic 2216 1.0\n",
      "\t\tOutcome: M5 231\n",
      "\t\t\tFeature Value, Count, and Prob: Manual 231 1.0\n",
      "\t\tOutcome: M6 2085\n",
      "\t\t\tFeature Value, Count, and Prob: Manual 2085 1.0\n",
      "\t\tOutcome: M7 412\n",
      "\t\t\tFeature Value, Count, and Prob: Automatic 412 1.0\n",
      "\t\tOutcome: M8 669\n",
      "\t\t\tFeature Value, Count, and Prob: Manual 669 1.0\n",
      "\t\tOutcome: M9 328\n",
      "\t\t\tFeature Value, Count, and Prob: Manual 328 1.0\n",
      "\tLikelihoods for: gear_box\n",
      "\t\tOutcome: M1 2282\n",
      "\t\t\tFeature Value, Count, and Prob: 5 2282 1.0\n",
      "\t\tOutcome: M10 161\n",
      "\t\t\tFeature Value, Count, and Prob: 5 161 1.0\n",
      "\t\tOutcome: M11 59\n",
      "\t\t\tFeature Value, Count, and Prob: 6 59 1.0\n",
      "\t\tOutcome: M2 159\n",
      "\t\t\tFeature Value, Count, and Prob: 5 159 1.0\n",
      "\t\tOutcome: M3 398\n",
      "\t\t\tFeature Value, Count, and Prob: 5 398 1.0\n",
      "\t\tOutcome: M4 2216\n",
      "\t\t\tFeature Value, Count, and Prob: 6 2216 1.0\n",
      "\t\tOutcome: M5 231\n",
      "\t\t\tFeature Value, Count, and Prob: 5 231 1.0\n",
      "\t\tOutcome: M6 2085\n",
      "\t\t\tFeature Value, Count, and Prob: 5 2085 1.0\n",
      "\t\tOutcome: M7 412\n",
      "\t\t\tFeature Value, Count, and Prob: 5 412 1.0\n",
      "\t\tOutcome: M8 669\n",
      "\t\t\tFeature Value, Count, and Prob: 5 669 1.0\n",
      "\t\tOutcome: M9 328\n",
      "\t\t\tFeature Value, Count, and Prob: 5 328 1.0\n",
      "\tLikelihoods for: steering_type\n",
      "\t\tOutcome: M1 2282\n",
      "\t\t\tFeature Value, Count, and Prob: Power 2282 1.0\n",
      "\t\tOutcome: M10 161\n",
      "\t\t\tFeature Value, Count, and Prob: Manual 161 1.0\n",
      "\t\tOutcome: M11 59\n",
      "\t\t\tFeature Value, Count, and Prob: Power 59 1.0\n",
      "\t\tOutcome: M2 159\n",
      "\t\t\tFeature Value, Count, and Prob: Electric 159 1.0\n",
      "\t\tOutcome: M3 398\n",
      "\t\t\tFeature Value, Count, and Prob: Electric 398 1.0\n",
      "\t\tOutcome: M4 2216\n",
      "\t\t\tFeature Value, Count, and Prob: Power 2216 1.0\n",
      "\t\tOutcome: M5 231\n",
      "\t\t\tFeature Value, Count, and Prob: Electric 231 1.0\n",
      "\t\tOutcome: M6 2085\n",
      "\t\t\tFeature Value, Count, and Prob: Electric 2085 1.0\n",
      "\t\tOutcome: M7 412\n",
      "\t\t\tFeature Value, Count, and Prob: Electric 412 1.0\n",
      "\t\tOutcome: M8 669\n",
      "\t\t\tFeature Value, Count, and Prob: Power 669 1.0\n",
      "\t\tOutcome: M9 328\n",
      "\t\t\tFeature Value, Count, and Prob: Electric 328 1.0\n",
      "\tLikelihoods for: is_front_fog_lights\n",
      "\t\tOutcome: M1 2282\n",
      "\t\t\tFeature Value, Count, and Prob: No 2282 1.0\n",
      "\t\tOutcome: M10 161\n",
      "\t\t\tFeature Value, Count, and Prob: No 161 1.0\n",
      "\t\tOutcome: M11 59\n",
      "\t\t\tFeature Value, Count, and Prob: No 59 1.0\n",
      "\t\tOutcome: M2 159\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 159 1.0\n",
      "\t\tOutcome: M3 398\n",
      "\t\t\tFeature Value, Count, and Prob: No 398 1.0\n",
      "\t\tOutcome: M4 2216\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2216 1.0\n",
      "\t\tOutcome: M5 231\n",
      "\t\t\tFeature Value, Count, and Prob: No 231 1.0\n",
      "\t\tOutcome: M6 2085\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2085 1.0\n",
      "\t\tOutcome: M7 412\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 412 1.0\n",
      "\t\tOutcome: M8 669\n",
      "\t\t\tFeature Value, Count, and Prob: No 669 1.0\n",
      "\t\tOutcome: M9 328\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 328 1.0\n",
      "\tLikelihoods for: is_rear_window_wiper\n",
      "\t\tOutcome: M1 2282\n",
      "\t\t\tFeature Value, Count, and Prob: No 2282 1.0\n",
      "\t\tOutcome: M10 161\n",
      "\t\t\tFeature Value, Count, and Prob: No 161 1.0\n",
      "\t\tOutcome: M11 59\n",
      "\t\t\tFeature Value, Count, and Prob: No 59 1.0\n",
      "\t\tOutcome: M2 159\n",
      "\t\t\tFeature Value, Count, and Prob: No 159 1.0\n",
      "\t\tOutcome: M3 398\n",
      "\t\t\tFeature Value, Count, and Prob: No 398 1.0\n",
      "\t\tOutcome: M4 2216\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2216 1.0\n",
      "\t\tOutcome: M5 231\n",
      "\t\t\tFeature Value, Count, and Prob: No 231 1.0\n",
      "\t\tOutcome: M6 2085\n",
      "\t\t\tFeature Value, Count, and Prob: No 2085 1.0\n",
      "\t\tOutcome: M7 412\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 412 1.0\n",
      "\t\tOutcome: M8 669\n",
      "\t\t\tFeature Value, Count, and Prob: No 669 1.0\n",
      "\t\tOutcome: M9 328\n",
      "\t\t\tFeature Value, Count, and Prob: No 328 1.0\n",
      "\tLikelihoods for: is_rear_window_washer\n",
      "\t\tOutcome: M1 2282\n",
      "\t\t\tFeature Value, Count, and Prob: No 2282 1.0\n",
      "\t\tOutcome: M10 161\n",
      "\t\t\tFeature Value, Count, and Prob: No 161 1.0\n",
      "\t\tOutcome: M11 59\n",
      "\t\t\tFeature Value, Count, and Prob: No 59 1.0\n",
      "\t\tOutcome: M2 159\n",
      "\t\t\tFeature Value, Count, and Prob: No 159 1.0\n",
      "\t\tOutcome: M3 398\n",
      "\t\t\tFeature Value, Count, and Prob: No 398 1.0\n",
      "\t\tOutcome: M4 2216\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2216 1.0\n",
      "\t\tOutcome: M5 231\n",
      "\t\t\tFeature Value, Count, and Prob: No 231 1.0\n",
      "\t\tOutcome: M6 2085\n",
      "\t\t\tFeature Value, Count, and Prob: No 2085 1.0\n",
      "\t\tOutcome: M7 412\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 412 1.0\n",
      "\t\tOutcome: M8 669\n",
      "\t\t\tFeature Value, Count, and Prob: No 669 1.0\n",
      "\t\tOutcome: M9 328\n",
      "\t\t\tFeature Value, Count, and Prob: No 328 1.0\n",
      "\tLikelihoods for: is_rear_window_defogger\n",
      "\t\tOutcome: M1 2282\n",
      "\t\t\tFeature Value, Count, and Prob: No 2282 1.0\n",
      "\t\tOutcome: M10 161\n",
      "\t\t\tFeature Value, Count, and Prob: No 161 1.0\n",
      "\t\tOutcome: M11 59\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 59 1.0\n",
      "\t\tOutcome: M2 159\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 159 1.0\n",
      "\t\tOutcome: M3 398\n",
      "\t\t\tFeature Value, Count, and Prob: No 398 1.0\n",
      "\t\tOutcome: M4 2216\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2216 1.0\n",
      "\t\tOutcome: M5 231\n",
      "\t\t\tFeature Value, Count, and Prob: No 231 1.0\n",
      "\t\tOutcome: M6 2085\n",
      "\t\t\tFeature Value, Count, and Prob: No 2085 1.0\n",
      "\t\tOutcome: M7 412\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 412 1.0\n",
      "\t\tOutcome: M8 669\n",
      "\t\t\tFeature Value, Count, and Prob: No 669 1.0\n",
      "\t\tOutcome: M9 328\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 328 1.0\n",
      "\tLikelihoods for: is_brake_assist\n",
      "\t\tOutcome: M1 2282\n",
      "\t\t\tFeature Value, Count, and Prob: No 2282 1.0\n",
      "\t\tOutcome: M10 161\n",
      "\t\t\tFeature Value, Count, and Prob: No 161 1.0\n",
      "\t\tOutcome: M11 59\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 59 1.0\n",
      "\t\tOutcome: M2 159\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 159 1.0\n",
      "\t\tOutcome: M3 398\n",
      "\t\t\tFeature Value, Count, and Prob: No 398 1.0\n",
      "\t\tOutcome: M4 2216\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2216 1.0\n",
      "\t\tOutcome: M5 231\n",
      "\t\t\tFeature Value, Count, and Prob: No 231 1.0\n",
      "\t\tOutcome: M6 2085\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2085 1.0\n",
      "\t\tOutcome: M7 412\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 412 1.0\n",
      "\t\tOutcome: M8 669\n",
      "\t\t\tFeature Value, Count, and Prob: No 669 1.0\n",
      "\t\tOutcome: M9 328\n",
      "\t\t\tFeature Value, Count, and Prob: No 328 1.0\n",
      "\tLikelihoods for: is_power_door_locks\n",
      "\t\tOutcome: M1 2282\n",
      "\t\t\tFeature Value, Count, and Prob: No 2282 1.0\n",
      "\t\tOutcome: M10 161\n",
      "\t\t\tFeature Value, Count, and Prob: No 161 1.0\n",
      "\t\tOutcome: M11 59\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 59 1.0\n",
      "\t\tOutcome: M2 159\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 159 1.0\n",
      "\t\tOutcome: M3 398\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 398 1.0\n",
      "\t\tOutcome: M4 2216\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2216 1.0\n",
      "\t\tOutcome: M5 231\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 231 1.0\n",
      "\t\tOutcome: M6 2085\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2085 1.0\n",
      "\t\tOutcome: M7 412\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 412 1.0\n",
      "\t\tOutcome: M8 669\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 669 1.0\n",
      "\t\tOutcome: M9 328\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 328 1.0\n",
      "\tLikelihoods for: is_central_locking\n",
      "\t\tOutcome: M1 2282\n",
      "\t\t\tFeature Value, Count, and Prob: No 2282 1.0\n",
      "\t\tOutcome: M10 161\n",
      "\t\t\tFeature Value, Count, and Prob: No 161 1.0\n",
      "\t\tOutcome: M11 59\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 59 1.0\n",
      "\t\tOutcome: M2 159\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 159 1.0\n",
      "\t\tOutcome: M3 398\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 398 1.0\n",
      "\t\tOutcome: M4 2216\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2216 1.0\n",
      "\t\tOutcome: M5 231\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 231 1.0\n",
      "\t\tOutcome: M6 2085\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2085 1.0\n",
      "\t\tOutcome: M7 412\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 412 1.0\n",
      "\t\tOutcome: M8 669\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 669 1.0\n",
      "\t\tOutcome: M9 328\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 328 1.0\n",
      "\tLikelihoods for: is_power_steering\n",
      "\t\tOutcome: M1 2282\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2282 1.0\n",
      "\t\tOutcome: M10 161\n",
      "\t\t\tFeature Value, Count, and Prob: No 161 1.0\n",
      "\t\tOutcome: M11 59\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 59 1.0\n",
      "\t\tOutcome: M2 159\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 159 1.0\n",
      "\t\tOutcome: M3 398\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 398 1.0\n",
      "\t\tOutcome: M4 2216\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2216 1.0\n",
      "\t\tOutcome: M5 231\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 231 1.0\n",
      "\t\tOutcome: M6 2085\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2085 1.0\n",
      "\t\tOutcome: M7 412\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 412 1.0\n",
      "\t\tOutcome: M8 669\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 669 1.0\n",
      "\t\tOutcome: M9 328\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 328 1.0\n",
      "\tLikelihoods for: is_driver_seat_height_adjustable\n",
      "\t\tOutcome: M1 2282\n",
      "\t\t\tFeature Value, Count, and Prob: No 2282 1.0\n",
      "\t\tOutcome: M10 161\n",
      "\t\t\tFeature Value, Count, and Prob: No 161 1.0\n",
      "\t\tOutcome: M11 59\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 59 1.0\n",
      "\t\tOutcome: M2 159\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 159 1.0\n",
      "\t\tOutcome: M3 398\n",
      "\t\t\tFeature Value, Count, and Prob: No 398 1.0\n",
      "\t\tOutcome: M4 2216\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2216 1.0\n",
      "\t\tOutcome: M5 231\n",
      "\t\t\tFeature Value, Count, and Prob: No 231 1.0\n",
      "\t\tOutcome: M6 2085\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2085 1.0\n",
      "\t\tOutcome: M7 412\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 412 1.0\n",
      "\t\tOutcome: M8 669\n",
      "\t\t\tFeature Value, Count, and Prob: No 669 1.0\n",
      "\t\tOutcome: M9 328\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 328 1.0\n",
      "\tLikelihoods for: is_day_night_rear_view_mirror\n",
      "\t\tOutcome: M1 2282\n",
      "\t\t\tFeature Value, Count, and Prob: No 2282 1.0\n",
      "\t\tOutcome: M10 161\n",
      "\t\t\tFeature Value, Count, and Prob: No 161 1.0\n",
      "\t\tOutcome: M11 59\n",
      "\t\t\tFeature Value, Count, and Prob: No 59 1.0\n",
      "\t\tOutcome: M2 159\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 159 1.0\n",
      "\t\tOutcome: M3 398\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 398 1.0\n",
      "\t\tOutcome: M4 2216\n",
      "\t\t\tFeature Value, Count, and Prob: No 2216 1.0\n",
      "\t\tOutcome: M5 231\n",
      "\t\t\tFeature Value, Count, and Prob: No 231 1.0\n",
      "\t\tOutcome: M6 2085\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2085 1.0\n",
      "\t\tOutcome: M7 412\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 412 1.0\n",
      "\t\tOutcome: M8 669\n",
      "\t\t\tFeature Value, Count, and Prob: No 669 1.0\n",
      "\t\tOutcome: M9 328\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 328 1.0\n",
      "\tLikelihoods for: is_ecw\n",
      "\t\tOutcome: M1 2282\n",
      "\t\t\tFeature Value, Count, and Prob: No 2282 1.0\n",
      "\t\tOutcome: M10 161\n",
      "\t\t\tFeature Value, Count, and Prob: No 161 1.0\n",
      "\t\tOutcome: M11 59\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 59 1.0\n",
      "\t\tOutcome: M2 159\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 159 1.0\n",
      "\t\tOutcome: M3 398\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 398 1.0\n",
      "\t\tOutcome: M4 2216\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2216 1.0\n",
      "\t\tOutcome: M5 231\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 231 1.0\n",
      "\t\tOutcome: M6 2085\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2085 1.0\n",
      "\t\tOutcome: M7 412\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 412 1.0\n",
      "\t\tOutcome: M8 669\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 669 1.0\n",
      "\t\tOutcome: M9 328\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 328 1.0\n",
      "\tLikelihoods for: is_speed_alert\n",
      "\t\tOutcome: M1 2282\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2282 1.0\n",
      "\t\tOutcome: M10 161\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 161 1.0\n",
      "\t\tOutcome: M11 59\n",
      "\t\t\tFeature Value, Count, and Prob: No 59 1.0\n",
      "\t\tOutcome: M2 159\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 159 1.0\n",
      "\t\tOutcome: M3 398\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 398 1.0\n",
      "\t\tOutcome: M4 2216\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2216 1.0\n",
      "\t\tOutcome: M5 231\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 231 1.0\n",
      "\t\tOutcome: M6 2085\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 2085 1.0\n",
      "\t\tOutcome: M7 412\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 412 1.0\n",
      "\t\tOutcome: M8 669\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 669 1.0\n",
      "\t\tOutcome: M9 328\n",
      "\t\t\tFeature Value, Count, and Prob: Yes 328 1.0\n",
      "\n",
      "Feature Priors:\n",
      "\tFeature: area_cluster\n",
      "\t\tValue, Count, and Prob: C8 2141 0.2378888888888889\n",
      "\t\tValue, Count, and Prob: C5 1117 0.12411111111111112\n",
      "\t\tValue, Count, and Prob: C2 1110 0.12333333333333334\n",
      "\t\tValue, Count, and Prob: C3 899 0.09988888888888889\n",
      "\t\tValue, Count, and Prob: C14 592 0.06577777777777778\n",
      "\t\tValue, Count, and Prob: C13 489 0.05433333333333333\n",
      "\t\tValue, Count, and Prob: C10 489 0.05433333333333333\n",
      "\t\tValue, Count, and Prob: C9 400 0.044444444444444446\n",
      "\t\tValue, Count, and Prob: C7 341 0.03788888888888889\n",
      "\t\tValue, Count, and Prob: C12 233 0.02588888888888889\n",
      "\t\tValue, Count, and Prob: C1 230 0.025555555555555557\n",
      "\t\tValue, Count, and Prob: C11 165 0.018333333333333333\n",
      "\t\tValue, Count, and Prob: C19 140 0.015555555555555555\n",
      "\t\tValue, Count, and Prob: C6 131 0.014555555555555556\n",
      "\t\tValue, Count, and Prob: C15 121 0.013444444444444445\n",
      "\t\tValue, Count, and Prob: C4 103 0.011444444444444445\n",
      "\t\tValue, Count, and Prob: C21 72 0.008\n",
      "\t\tValue, Count, and Prob: C16 69 0.007666666666666666\n",
      "\t\tValue, Count, and Prob: C17 65 0.007222222222222222\n",
      "\t\tValue, Count, and Prob: C18 38 0.004222222222222222\n",
      "\t\tValue, Count, and Prob: C22 28 0.003111111111111111\n",
      "\t\tValue, Count, and Prob: C20 27 0.003\n",
      "\tFeature: make\n",
      "\t\tValue, Count, and Prob: 1 5768 0.6408888888888888\n",
      "\t\tValue, Count, and Prob: 3 2216 0.24622222222222223\n",
      "\t\tValue, Count, and Prob: 2 398 0.044222222222222225\n",
      "\t\tValue, Count, and Prob: 5 328 0.036444444444444446\n",
      "\t\tValue, Count, and Prob: 4 290 0.03222222222222222\n",
      "\tFeature: segment\n",
      "\t\tValue, Count, and Prob: B2 2728 0.3031111111111111\n",
      "\t\tValue, Count, and Prob: A 2680 0.29777777777777775\n",
      "\t\tValue, Count, and Prob: C2 2216 0.24622222222222223\n",
      "\t\tValue, Count, and Prob: B1 669 0.07433333333333333\n",
      "\t\tValue, Count, and Prob: C1 546 0.06066666666666667\n",
      "\t\tValue, Count, and Prob: Utility 161 0.017888888888888888\n",
      "\tFeature: fuel_type\n",
      "\t\tValue, Count, and Prob: Petrol 3113 0.3458888888888889\n",
      "\t\tValue, Count, and Prob: CNG 3112 0.3457777777777778\n",
      "\t\tValue, Count, and Prob: Diesel 2775 0.30833333333333335\n",
      "\tFeature: is_esc\n",
      "\t\tValue, Count, and Prob: No 6154 0.6837777777777778\n",
      "\t\tValue, Count, and Prob: Yes 2846 0.31622222222222224\n",
      "\tFeature: is_adjustable_steering\n",
      "\t\tValue, Count, and Prob: Yes 5431 0.6034444444444444\n",
      "\t\tValue, Count, and Prob: No 3569 0.39655555555555555\n",
      "\tFeature: is_tpms\n",
      "\t\tValue, Count, and Prob: No 6784 0.7537777777777778\n",
      "\t\tValue, Count, and Prob: Yes 2216 0.24622222222222223\n",
      "\tFeature: is_parking_sensors\n",
      "\t\tValue, Count, and Prob: Yes 8602 0.9557777777777777\n",
      "\t\tValue, Count, and Prob: No 398 0.044222222222222225\n",
      "\tFeature: is_parking_camera\n",
      "\t\tValue, Count, and Prob: No 5428 0.6031111111111112\n",
      "\t\tValue, Count, and Prob: Yes 3572 0.3968888888888889\n",
      "\tFeature: rear_brakes_type\n",
      "\t\tValue, Count, and Prob: Drum 6784 0.7537777777777778\n",
      "\t\tValue, Count, and Prob: Disc 2216 0.24622222222222223\n",
      "\tFeature: transmission_type\n",
      "\t\tValue, Count, and Prob: Manual 5815 0.6461111111111111\n",
      "\t\tValue, Count, and Prob: Automatic 3185 0.35388888888888886\n",
      "\tFeature: gear_box\n",
      "\t\tValue, Count, and Prob: 5 6725 0.7472222222222222\n",
      "\t\tValue, Count, and Prob: 6 2275 0.25277777777777777\n",
      "\tFeature: steering_type\n",
      "\t\tValue, Count, and Prob: Power 5226 0.5806666666666667\n",
      "\t\tValue, Count, and Prob: Electric 3613 0.40144444444444444\n",
      "\t\tValue, Count, and Prob: Manual 161 0.017888888888888888\n",
      "\tFeature: is_front_fog_lights\n",
      "\t\tValue, Count, and Prob: Yes 5200 0.5777777777777777\n",
      "\t\tValue, Count, and Prob: No 3800 0.4222222222222222\n",
      "\tFeature: is_rear_window_wiper\n",
      "\t\tValue, Count, and Prob: No 6372 0.708\n",
      "\t\tValue, Count, and Prob: Yes 2628 0.292\n",
      "\tFeature: is_rear_window_washer\n",
      "\t\tValue, Count, and Prob: No 6372 0.708\n",
      "\t\tValue, Count, and Prob: Yes 2628 0.292\n",
      "\tFeature: is_rear_window_defogger\n",
      "\t\tValue, Count, and Prob: No 5826 0.6473333333333333\n",
      "\t\tValue, Count, and Prob: Yes 3174 0.3526666666666667\n",
      "\tFeature: is_brake_assist\n",
      "\t\tValue, Count, and Prob: Yes 4931 0.5478888888888889\n",
      "\t\tValue, Count, and Prob: No 4069 0.45211111111111113\n",
      "\tFeature: is_power_door_locks\n",
      "\t\tValue, Count, and Prob: Yes 6557 0.7285555555555555\n",
      "\t\tValue, Count, and Prob: No 2443 0.27144444444444443\n",
      "\tFeature: is_central_locking\n",
      "\t\tValue, Count, and Prob: Yes 6557 0.7285555555555555\n",
      "\t\tValue, Count, and Prob: No 2443 0.27144444444444443\n",
      "\tFeature: is_power_steering\n",
      "\t\tValue, Count, and Prob: Yes 8839 0.9821111111111112\n",
      "\t\tValue, Count, and Prob: No 161 0.017888888888888888\n",
      "\tFeature: is_driver_seat_height_adjustable\n",
      "\t\tValue, Count, and Prob: Yes 5259 0.5843333333333334\n",
      "\t\tValue, Count, and Prob: No 3741 0.4156666666666667\n",
      "\tFeature: is_day_night_rear_view_mirror\n",
      "\t\tValue, Count, and Prob: No 5618 0.6242222222222222\n",
      "\t\tValue, Count, and Prob: Yes 3382 0.37577777777777777\n",
      "\tFeature: is_ecw\n",
      "\t\tValue, Count, and Prob: Yes 6557 0.7285555555555555\n",
      "\t\tValue, Count, and Prob: No 2443 0.27144444444444443\n",
      "\tFeature: is_speed_alert\n",
      "\t\tValue, Count, and Prob: Yes 8941 0.9934444444444445\n",
      "\t\tValue, Count, and Prob: No 59 0.006555555555555556\n",
      "\n",
      "Predictions:\n",
      "Test Accuracy: 0.996\n"
     ]
    }
   ],
   "source": [
    "x2, y2 = pre_processing(df2)\n",
    "\n",
    "columns = df2.columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x2, y2, test_size=0.1, stratify=y2, random_state=42)\n",
    "nb_2 = NaiveBayes()\n",
    "nb_2.fit(X_train, y_train)\n",
    "\n",
    "print(\"Test Accuracy: {}\".format(accuracy_score(y_test, nb_2.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Predict the \"outcome\" using the Naive Bayes algorithm above. If you're keen, try the sklearn one as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>industry</th>\n",
       "      <th>profession</th>\n",
       "      <th>traffic</th>\n",
       "      <th>coach</th>\n",
       "      <th>head_gender</th>\n",
       "      <th>greywage</th>\n",
       "      <th>way</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m</td>\n",
       "      <td>Banks</td>\n",
       "      <td>HR</td>\n",
       "      <td>rabrecNErab</td>\n",
       "      <td>no</td>\n",
       "      <td>f</td>\n",
       "      <td>white</td>\n",
       "      <td>bus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m</td>\n",
       "      <td>Banks</td>\n",
       "      <td>HR</td>\n",
       "      <td>empjs</td>\n",
       "      <td>no</td>\n",
       "      <td>m</td>\n",
       "      <td>white</td>\n",
       "      <td>bus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f</td>\n",
       "      <td>PowerGeneration</td>\n",
       "      <td>HR</td>\n",
       "      <td>rabrecNErab</td>\n",
       "      <td>no</td>\n",
       "      <td>m</td>\n",
       "      <td>white</td>\n",
       "      <td>bus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f</td>\n",
       "      <td>PowerGeneration</td>\n",
       "      <td>HR</td>\n",
       "      <td>rabrecNErab</td>\n",
       "      <td>no</td>\n",
       "      <td>m</td>\n",
       "      <td>white</td>\n",
       "      <td>bus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>youjs</td>\n",
       "      <td>yes</td>\n",
       "      <td>f</td>\n",
       "      <td>white</td>\n",
       "      <td>bus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender         industry  profession      traffic coach head_gender greywage  \\\n",
       "0      m            Banks          HR  rabrecNErab    no           f    white   \n",
       "1      m            Banks          HR        empjs    no           m    white   \n",
       "2      f  PowerGeneration          HR  rabrecNErab    no           m    white   \n",
       "3      f  PowerGeneration          HR  rabrecNErab    no           m    white   \n",
       "4      m           Retail  Commercial        youjs   yes           f    white   \n",
       "\n",
       "   way outcome  \n",
       "0  bus       1  \n",
       "1  bus       1  \n",
       "2  bus       1  \n",
       "3  bus       1  \n",
       "4  bus       1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.read_csv(\"data/turnover.csv\",encoding = \"ISO-8859-1\")\n",
    "df3[\"outcome\"] = df3[\"event\"].astype(\"string\")\n",
    "df3.drop(columns={\"stag\", \"extraversion\", \"independ\", \"selfcontrol\", \"anxiety\", \"novator\", \"age\", \"event\"}, inplace=True)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='outcome', ylabel='count'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data=df3, x=\"outcome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1129 entries, 0 to 1128\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   gender       1129 non-null   object\n",
      " 1   industry     1129 non-null   object\n",
      " 2   profession   1129 non-null   object\n",
      " 3   traffic      1129 non-null   object\n",
      " 4   coach        1129 non-null   object\n",
      " 5   head_gender  1129 non-null   object\n",
      " 6   greywage     1129 non-null   object\n",
      " 7   way          1129 non-null   object\n",
      " 8   outcome      1129 non-null   string\n",
      "dtypes: object(8), string(1)\n",
      "memory usage: 79.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model\n",
    "\n",
    "Train model and test accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outcome Priors:\n",
      "0 427\n",
      "1 419\n",
      "\n",
      "Likelihoods:\n",
      "\tLikelihoods for: gender\n",
      "\t\tOutcome: 0 427\n",
      "\t\t\tFeature Value, Count, and Prob: f 317 0.7423887587822015\n",
      "\t\t\tFeature Value, Count, and Prob: m 110 0.2576112412177986\n",
      "\t\tOutcome: 1 419\n",
      "\t\t\tFeature Value, Count, and Prob: f 314 0.7494033412887828\n",
      "\t\t\tFeature Value, Count, and Prob: m 105 0.25059665871121717\n",
      "\tLikelihoods for: industry\n",
      "\t\tOutcome: 0 427\n",
      "\t\t\tFeature Value, Count, and Prob: Retail 122 0.2857142857142857\n",
      "\t\t\tFeature Value, Count, and Prob: IT 64 0.14988290398126464\n",
      "\t\t\tFeature Value, Count, and Prob: manufacture 58 0.1358313817330211\n",
      "\t\t\tFeature Value, Count, and Prob: Banks 28 0.06557377049180328\n",
      "\t\t\tFeature Value, Count, and Prob: etc 27 0.06323185011709602\n",
      "\t\t\tFeature Value, Count, and Prob: PowerGeneration 21 0.04918032786885246\n",
      "\t\t\tFeature Value, Count, and Prob: Consult 20 0.0468384074941452\n",
      "\t\t\tFeature Value, Count, and Prob: State 19 0.04449648711943794\n",
      "\t\t\tFeature Value, Count, and Prob: Telecom 14 0.03278688524590164\n",
      "\t\t\tFeature Value, Count, and Prob: transport 13 0.03044496487119438\n",
      "\t\t\tFeature Value, Count, and Prob: Pharma 9 0.02107728337236534\n",
      "\t\t\tFeature Value, Count, and Prob: Mining 8 0.01873536299765808\n",
      "\t\t\tFeature Value, Count, and Prob: Building 8 0.01873536299765808\n",
      "\t\t\tFeature Value, Count, and Prob: RealEstate 7 0.01639344262295082\n",
      "\t\t\tFeature Value, Count, and Prob:  HoReCa 5 0.0117096018735363\n",
      "\t\t\tFeature Value, Count, and Prob: Agriculture 4 0.00936768149882904\n",
      "\t\tOutcome: 1 419\n",
      "\t\t\tFeature Value, Count, and Prob: Retail 108 0.2577565632458234\n",
      "\t\t\tFeature Value, Count, and Prob: Banks 57 0.1360381861575179\n",
      "\t\t\tFeature Value, Count, and Prob: manufacture 51 0.12171837708830549\n",
      "\t\t\tFeature Value, Count, and Prob: etc 36 0.08591885441527446\n",
      "\t\t\tFeature Value, Count, and Prob: Consult 28 0.06682577565632458\n",
      "\t\t\tFeature Value, Count, and Prob: IT 26 0.06205250596658711\n",
      "\t\t\tFeature Value, Count, and Prob: State 25 0.059665871121718374\n",
      "\t\t\tFeature Value, Count, and Prob: Building 20 0.0477326968973747\n",
      "\t\t\tFeature Value, Count, and Prob: PowerGeneration 14 0.03341288782816229\n",
      "\t\t\tFeature Value, Count, and Prob: transport 12 0.028639618138424822\n",
      "\t\t\tFeature Value, Count, and Prob: Telecom 12 0.028639618138424822\n",
      "\t\t\tFeature Value, Count, and Prob: Mining 9 0.021479713603818614\n",
      "\t\t\tFeature Value, Count, and Prob: Pharma 9 0.021479713603818614\n",
      "\t\t\tFeature Value, Count, and Prob: Agriculture 5 0.011933174224343675\n",
      "\t\t\tFeature Value, Count, and Prob: RealEstate 4 0.00954653937947494\n",
      "\t\t\tFeature Value, Count, and Prob:  HoReCa 3 0.007159904534606206\n",
      "\tLikelihoods for: profession\n",
      "\t\tOutcome: 0 427\n",
      "\t\t\tFeature Value, Count, and Prob: HR 305 0.7142857142857143\n",
      "\t\t\tFeature Value, Count, and Prob: IT 35 0.08196721311475409\n",
      "\t\t\tFeature Value, Count, and Prob: Sales 26 0.06088992974238876\n",
      "\t\t\tFeature Value, Count, and Prob: etc 13 0.03044496487119438\n",
      "\t\t\tFeature Value, Count, and Prob: BusinessDevelopment 10 0.0234192037470726\n",
      "\t\t\tFeature Value, Count, and Prob: Commercial 8 0.01873536299765808\n",
      "\t\t\tFeature Value, Count, and Prob: Marketing 7 0.01639344262295082\n",
      "\t\t\tFeature Value, Count, and Prob: Consult 6 0.01405152224824356\n",
      "\t\t\tFeature Value, Count, and Prob: manage 6 0.01405152224824356\n",
      "\t\t\tFeature Value, Count, and Prob: Engineer 3 0.00702576112412178\n",
      "\t\t\tFeature Value, Count, and Prob: Finanñe 3 0.00702576112412178\n",
      "\t\t\tFeature Value, Count, and Prob: Accounting 2 0.00468384074941452\n",
      "\t\t\tFeature Value, Count, and Prob: Law 2 0.00468384074941452\n",
      "\t\t\tFeature Value, Count, and Prob: PR 1 0.00234192037470726\n",
      "\t\tOutcome: 1 419\n",
      "\t\t\tFeature Value, Count, and Prob: HR 266 0.6348448687350835\n",
      "\t\t\tFeature Value, Count, and Prob: Sales 26 0.06205250596658711\n",
      "\t\t\tFeature Value, Count, and Prob: IT 19 0.045346062052505964\n",
      "\t\t\tFeature Value, Count, and Prob: Marketing 15 0.03579952267303103\n",
      "\t\t\tFeature Value, Count, and Prob: BusinessDevelopment 13 0.031026252983293555\n",
      "\t\t\tFeature Value, Count, and Prob: manage 12 0.028639618138424822\n",
      "\t\t\tFeature Value, Count, and Prob: etc 12 0.028639618138424822\n",
      "\t\t\tFeature Value, Count, and Prob: Commercial 12 0.028639618138424822\n",
      "\t\t\tFeature Value, Count, and Prob: Consult 9 0.021479713603818614\n",
      "\t\t\tFeature Value, Count, and Prob: Finanñe 9 0.021479713603818614\n",
      "\t\t\tFeature Value, Count, and Prob: Teaching 7 0.016706443914081145\n",
      "\t\t\tFeature Value, Count, and Prob: PR 5 0.011933174224343675\n",
      "\t\t\tFeature Value, Count, and Prob: Engineer 5 0.011933174224343675\n",
      "\t\t\tFeature Value, Count, and Prob: Accounting 5 0.011933174224343675\n",
      "\t\t\tFeature Value, Count, and Prob: Law 4 0.00954653937947494\n",
      "\tLikelihoods for: traffic\n",
      "\t\tOutcome: 0 427\n",
      "\t\t\tFeature Value, Count, and Prob: youjs 135 0.3161592505854801\n",
      "\t\t\tFeature Value, Count, and Prob: empjs 89 0.20843091334894615\n",
      "\t\t\tFeature Value, Count, and Prob: rabrecNErab 63 0.14754098360655737\n",
      "\t\t\tFeature Value, Count, and Prob: friends 56 0.13114754098360656\n",
      "\t\t\tFeature Value, Count, and Prob: referal 28 0.06557377049180328\n",
      "\t\t\tFeature Value, Count, and Prob: KA 22 0.05152224824355972\n",
      "\t\t\tFeature Value, Count, and Prob: advert 17 0.03981264637002342\n",
      "\t\t\tFeature Value, Count, and Prob: recNErab 17 0.03981264637002342\n",
      "\t\tOutcome: 1 419\n",
      "\t\t\tFeature Value, Count, and Prob: rabrecNErab 103 0.2458233890214797\n",
      "\t\t\tFeature Value, Count, and Prob: youjs 103 0.2458233890214797\n",
      "\t\t\tFeature Value, Count, and Prob: empjs 88 0.2100238663484487\n",
      "\t\t\tFeature Value, Count, and Prob: referal 44 0.10501193317422435\n",
      "\t\t\tFeature Value, Count, and Prob: friends 31 0.07398568019093078\n",
      "\t\t\tFeature Value, Count, and Prob: KA 28 0.06682577565632458\n",
      "\t\t\tFeature Value, Count, and Prob: recNErab 13 0.031026252983293555\n",
      "\t\t\tFeature Value, Count, and Prob: advert 9 0.021479713603818614\n",
      "\tLikelihoods for: coach\n",
      "\t\tOutcome: 0 427\n",
      "\t\t\tFeature Value, Count, and Prob: no 259 0.6065573770491803\n",
      "\t\t\tFeature Value, Count, and Prob: my head 124 0.2903981264637002\n",
      "\t\t\tFeature Value, Count, and Prob: yes 44 0.10304449648711944\n",
      "\t\tOutcome: 1 419\n",
      "\t\t\tFeature Value, Count, and Prob: no 250 0.5966587112171837\n",
      "\t\t\tFeature Value, Count, and Prob: my head 110 0.26252983293556087\n",
      "\t\t\tFeature Value, Count, and Prob: yes 59 0.14081145584725538\n",
      "\tLikelihoods for: head_gender\n",
      "\t\tOutcome: 0 427\n",
      "\t\t\tFeature Value, Count, and Prob: f 216 0.5058548009367682\n",
      "\t\t\tFeature Value, Count, and Prob: m 211 0.49414519906323184\n",
      "\t\tOutcome: 1 419\n",
      "\t\t\tFeature Value, Count, and Prob: m 237 0.5656324582338902\n",
      "\t\t\tFeature Value, Count, and Prob: f 182 0.4343675417661098\n",
      "\tLikelihoods for: greywage\n",
      "\t\tOutcome: 0 427\n",
      "\t\t\tFeature Value, Count, and Prob: white 388 0.9086651053864169\n",
      "\t\t\tFeature Value, Count, and Prob: grey 39 0.09133489461358314\n",
      "\t\tOutcome: 1 419\n",
      "\t\t\tFeature Value, Count, and Prob: white 367 0.8758949880668258\n",
      "\t\t\tFeature Value, Count, and Prob: grey 52 0.12410501193317422\n",
      "\tLikelihoods for: way\n",
      "\t\tOutcome: 0 427\n",
      "\t\t\tFeature Value, Count, and Prob: bus 243 0.5690866510538641\n",
      "\t\t\tFeature Value, Count, and Prob: car 127 0.297423887587822\n",
      "\t\t\tFeature Value, Count, and Prob: foot 57 0.13348946135831383\n",
      "\t\tOutcome: 1 419\n",
      "\t\t\tFeature Value, Count, and Prob: bus 259 0.6181384248210023\n",
      "\t\t\tFeature Value, Count, and Prob: car 132 0.315035799522673\n",
      "\t\t\tFeature Value, Count, and Prob: foot 28 0.06682577565632458\n",
      "\n",
      "Feature Priors:\n",
      "\tFeature: gender\n",
      "\t\tValue, Count, and Prob: f 631 0.7458628841607565\n",
      "\t\tValue, Count, and Prob: m 215 0.2541371158392435\n",
      "\tFeature: industry\n",
      "\t\tValue, Count, and Prob: Retail 230 0.2718676122931442\n",
      "\t\tValue, Count, and Prob: manufacture 109 0.1288416075650118\n",
      "\t\tValue, Count, and Prob: IT 90 0.10638297872340426\n",
      "\t\tValue, Count, and Prob: Banks 85 0.10047281323877069\n",
      "\t\tValue, Count, and Prob: etc 63 0.07446808510638298\n",
      "\t\tValue, Count, and Prob: Consult 48 0.05673758865248227\n",
      "\t\tValue, Count, and Prob: State 44 0.05200945626477541\n",
      "\t\tValue, Count, and Prob: PowerGeneration 35 0.041371158392434985\n",
      "\t\tValue, Count, and Prob: Building 28 0.03309692671394799\n",
      "\t\tValue, Count, and Prob: Telecom 26 0.030732860520094562\n",
      "\t\tValue, Count, and Prob: transport 25 0.02955082742316785\n",
      "\t\tValue, Count, and Prob: Pharma 18 0.02127659574468085\n",
      "\t\tValue, Count, and Prob: Mining 17 0.02009456264775414\n",
      "\t\tValue, Count, and Prob: RealEstate 11 0.013002364066193853\n",
      "\t\tValue, Count, and Prob: Agriculture 9 0.010638297872340425\n",
      "\t\tValue, Count, and Prob:  HoReCa 8 0.009456264775413711\n",
      "\tFeature: profession\n",
      "\t\tValue, Count, and Prob: HR 571 0.6749408983451537\n",
      "\t\tValue, Count, and Prob: IT 54 0.06382978723404255\n",
      "\t\tValue, Count, and Prob: Sales 52 0.061465721040189124\n",
      "\t\tValue, Count, and Prob: etc 25 0.02955082742316785\n",
      "\t\tValue, Count, and Prob: BusinessDevelopment 23 0.027186761229314422\n",
      "\t\tValue, Count, and Prob: Marketing 22 0.026004728132387706\n",
      "\t\tValue, Count, and Prob: Commercial 20 0.02364066193853428\n",
      "\t\tValue, Count, and Prob: manage 18 0.02127659574468085\n",
      "\t\tValue, Count, and Prob: Consult 15 0.01773049645390071\n",
      "\t\tValue, Count, and Prob: Finanñe 12 0.014184397163120567\n",
      "\t\tValue, Count, and Prob: Engineer 8 0.009456264775413711\n",
      "\t\tValue, Count, and Prob: Teaching 7 0.008274231678486997\n",
      "\t\tValue, Count, and Prob: Accounting 7 0.008274231678486997\n",
      "\t\tValue, Count, and Prob: Law 6 0.0070921985815602835\n",
      "\t\tValue, Count, and Prob: PR 6 0.0070921985815602835\n",
      "\tFeature: traffic\n",
      "\t\tValue, Count, and Prob: youjs 238 0.28132387706855794\n",
      "\t\tValue, Count, and Prob: empjs 177 0.20921985815602837\n",
      "\t\tValue, Count, and Prob: rabrecNErab 166 0.19621749408983452\n",
      "\t\tValue, Count, and Prob: friends 87 0.10283687943262411\n",
      "\t\tValue, Count, and Prob: referal 72 0.0851063829787234\n",
      "\t\tValue, Count, and Prob: KA 50 0.0591016548463357\n",
      "\t\tValue, Count, and Prob: recNErab 30 0.03546099290780142\n",
      "\t\tValue, Count, and Prob: advert 26 0.030732860520094562\n",
      "\tFeature: coach\n",
      "\t\tValue, Count, and Prob: no 509 0.6016548463356974\n",
      "\t\tValue, Count, and Prob: my head 234 0.2765957446808511\n",
      "\t\tValue, Count, and Prob: yes 103 0.12174940898345153\n",
      "\tFeature: head_gender\n",
      "\t\tValue, Count, and Prob: m 448 0.5295508274231678\n",
      "\t\tValue, Count, and Prob: f 398 0.47044917257683216\n",
      "\tFeature: greywage\n",
      "\t\tValue, Count, and Prob: white 755 0.892434988179669\n",
      "\t\tValue, Count, and Prob: grey 91 0.10756501182033097\n",
      "\tFeature: way\n",
      "\t\tValue, Count, and Prob: bus 502 0.5933806146572104\n",
      "\t\tValue, Count, and Prob: car 259 0.3061465721040189\n",
      "\t\tValue, Count, and Prob: foot 85 0.10047281323877069\n",
      "\n",
      "Predictions:\n",
      "Test Accuracy: 0.6219081272084805\n"
     ]
    }
   ],
   "source": [
    "x3, y3 = pre_processing(df3)\n",
    "\n",
    "columns = df3.columns\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(x3, y3)\n",
    "nb_3 = NaiveBayes()\n",
    "nb_3.fit(X_train3, y_train3)\n",
    "\n",
    "print(\"Test Accuracy: {}\".format(accuracy_score(y_test3, nb_3.predict(X_test3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model with SKlearn\n",
    "\n",
    "Note, you may need to prep the data a bit more. I used the OrdinalEncoder to encode the categorical values. From the sklearn documentation, \"It is further assumed that all categories of each feature are represented by the numbers 0, …, n - 1, where n refers to the total number of categories for the given feature. This can, for instance, be achieved with the help of OrdinalEncoder.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5795053003533569\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "y4 = np.array(df3[\"outcome\"]).reshape(-1,1)\n",
    "x4 = np.array(df3.drop(columns={\"outcome\"}))\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(x4, y4)\n",
    "\n",
    "model = CategoricalNB().fit(encoder.fit_transform(X_train4), y_train4.ravel())\n",
    "preds = model.predict(encoder.transform(X_test4))\n",
    "\n",
    "print(\"Test Accuracy: {}\".format(accuracy_score(y_test4, preds)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40846f95e88ae24f681f7d79d7396bca459ce37b2ecada686cfbc3bbe9daaf0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
